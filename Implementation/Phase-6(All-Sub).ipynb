{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42206b2e-8693-44d0-8687-50321a50d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# Phase 6 FINAL — Train ONE model on ALL subjects (single ckpt)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, math, json, time, random, argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "\n",
    "class CFG:\n",
    "    ROOT_DIR    = Path(r\"/home/tsultan1/BioRob(Final)/Data\")\n",
    "    DATASET_DIR = ROOT_DIR / \"_dataset_icml_v1\"\n",
    "\n",
    "    SSL_PREFIX      = \"exports_v1_ssl\"         # Phase-5 SSL shards\n",
    "    BAL_PREFIX      = \"exports_v1_balanced\"    # Phase-5 balanced shards\n",
    "\n",
    "    TASK_CODES      = [0, 1, 2, 3, 4, 5]       # must include REST=0\n",
    "\n",
    "    DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    NUM_WORKERS = 2\n",
    "\n",
    "    # ---- FINAL training split inside \"all data\" ----\n",
    "    VAL_FRAC    = 0.08      # small internal val for early-stop + threshold tune\n",
    "    SEED        = 42\n",
    "\n",
    "    # ---- SSL (Stage 1) ----\n",
    "    USE_SSL     = True\n",
    "    SSL_EPOCHS  = 35\n",
    "    SSL_BATCH   = 64\n",
    "    SSL_LR      = 1e-3\n",
    "    SSL_MAX_WINDOWS = 6000      # subsample to speed up if needed\n",
    "    SSL_MASK_PROB   = 0.15\n",
    "    SSL_TEMP        = 0.1\n",
    "    SSL_MODAL_DROPOUT = 0.25\n",
    "\n",
    "    LAMBDA_MASK     = 1.0\n",
    "    LAMBDA_CONTRAST = 0.6\n",
    "    LAMBDA_XMOD     = 0.25\n",
    "\n",
    "    # ---- Supervised (Stage 2) ----\n",
    "    SUP_EPOCHS   = 55\n",
    "    SUP_BATCH    = 64\n",
    "    SUP_LR       = 2e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    BACKBONE_LR_SCALE = 0.15\n",
    "\n",
    "    # Warm-start stability\n",
    "    FREEZE_BACKBONE_EPOCHS = 4  # train heads first, then unfreeze\n",
    "\n",
    "    # Loss weights\n",
    "    ALPHA_ACTION = 0.35\n",
    "    BETA_TASK    = 0.65\n",
    "\n",
    "    # Model\n",
    "    D_MODEL      = 128\n",
    "    DROPOUT      = 0.20\n",
    "    N_HEADS_FUSE = 4\n",
    "    N_LAYERS_FUSE = 2\n",
    "    POOL_STRIDE   = 2\n",
    "\n",
    "    # Regularization to avoid over-relying on ET\n",
    "    SUP_ET_DROPOUT = 0.10\n",
    "\n",
    "    # Training quality\n",
    "    GRAD_CLIP  = 1.0\n",
    "    USE_AMP    = True\n",
    "    USE_EMA    = True\n",
    "    EMA_DECAY  = 0.995\n",
    "\n",
    "    # Threshold tuning\n",
    "    THRESH_GRID = [round(x, 2) for x in np.linspace(0.10, 0.90, 17)]\n",
    "\n",
    "    # Phase 5.5 features (optional)\n",
    "    USE_EEG_PSD_FEATURES = True\n",
    "    USE_EMG_FEATURES     = True\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(CFG.SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# ---------------- SMALL UTILITIES ----------------\n",
    "\n",
    "def discover_folds(prefix: str) -> List[int]:\n",
    "    folds = []\n",
    "    for p in CFG.DATASET_DIR.glob(f\"{prefix}_fold*\"):\n",
    "        try:\n",
    "            fid = int(p.name.split(\"fold\")[-1])\n",
    "            folds.append(fid)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return sorted(set(folds))\n",
    "\n",
    "\n",
    "def stratified_split_indices(y: np.ndarray, val_frac: float, seed: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simple stratified split by y (e.g., y_task). Avoids sklearn dependency.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    y = np.asarray(y).astype(int)\n",
    "\n",
    "    train_idx, val_idx = [], []\n",
    "    for cls in np.unique(y):\n",
    "        idx = np.where(y == cls)[0]\n",
    "        rng.shuffle(idx)\n",
    "        n_val = max(1, int(round(len(idx) * val_frac)))\n",
    "        val_idx.append(idx[:n_val])\n",
    "        train_idx.append(idx[n_val:])\n",
    "    train_idx = np.concatenate(train_idx) if train_idx else np.array([], dtype=int)\n",
    "    val_idx   = np.concatenate(val_idx) if val_idx else np.array([], dtype=int)\n",
    "    rng.shuffle(train_idx)\n",
    "    rng.shuffle(val_idx)\n",
    "    return train_idx, val_idx\n",
    "\n",
    "\n",
    "# ---------------- DATASET LOADER (ALL SPLITS OF ONE FOLD) ----------------\n",
    "\n",
    "class AllSplitsShardDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads a SINGLE fold's shards from split dirs and concatenates:\n",
    "      {fold_dir}/{train,val,test}/*_shard_*.npz\n",
    "\n",
    "    Supports:\n",
    "      - ssl_mode=True  -> keep all windows\n",
    "      - ssl_mode=False -> keep windows with y_task in TASK_CODES\n",
    "      - optional Phase 5.5 features per split:\n",
    "          features_v1_eeg_psd_full_fold{fid}_{split}.npz  (X_psd, X_emg)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        fold_dir: Path,\n",
    "        fold_id: int,\n",
    "        splits: List[str],\n",
    "        ssl_mode: bool,\n",
    "        max_windows: Optional[int] = None,\n",
    "        attach_features: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fold_dir = Path(fold_dir)\n",
    "        self.fold_id = int(fold_id)\n",
    "        self.splits = list(splits)\n",
    "        self.ssl_mode = bool(ssl_mode)\n",
    "\n",
    "        X_eeg_list, X_emg_list, X_et_list = [], [], []\n",
    "        y_action_list, y_task_list = [], []\n",
    "\n",
    "        X_psd_list, X_emgfeat_list = [], []\n",
    "        self.has_features = False\n",
    "\n",
    "        for split in self.splits:\n",
    "            split_dir = self.fold_dir / split\n",
    "            if not split_dir.exists():\n",
    "                raise FileNotFoundError(f\"Missing split dir: {split_dir}\")\n",
    "\n",
    "            shard_paths = sorted(split_dir.glob(\"*_shard_*.npz\"))\n",
    "            if not shard_paths:\n",
    "                raise FileNotFoundError(f\"No shards in: {split_dir}\")\n",
    "\n",
    "            # (Optional) load features for this split (Phase 5.5)\n",
    "            X_psd_split = X_emg_split = None\n",
    "            if attach_features:\n",
    "                feat_path = CFG.DATASET_DIR / f\"features_v1_eeg_psd_full_fold{self.fold_id}_{split}.npz\"\n",
    "                if feat_path.exists():\n",
    "                    zf = np.load(feat_path, allow_pickle=True)\n",
    "                    X_psd_split = zf[\"X_psd\"].astype(np.float32)\n",
    "                    X_emg_split = zf[\"X_emg\"].astype(np.float32)\n",
    "\n",
    "            # Load shards for this split, preserving shard order\n",
    "            X_eeg_s, X_emg_s, X_et_s = [], [], []\n",
    "            y_action_s, y_task_s = [], []\n",
    "\n",
    "            for sp in shard_paths:\n",
    "                z = np.load(sp, allow_pickle=True)\n",
    "                Xeeg = z[\"X_EEG\"]\n",
    "                Xemg = z[\"X_EMG\"]\n",
    "                Xet  = z[\"X_ET\"]\n",
    "                ya   = z[\"y_action\"].astype(np.int64)\n",
    "                yt   = z[\"y_task\"].astype(np.int64)\n",
    "\n",
    "                N = yt.shape[0]\n",
    "                if N == 0:\n",
    "                    continue\n",
    "\n",
    "                if self.ssl_mode:\n",
    "                    keep = np.ones(N, dtype=bool)\n",
    "                else:\n",
    "                    keep = np.isin(yt, np.array(CFG.TASK_CODES, dtype=np.int64))\n",
    "\n",
    "                if not keep.any():\n",
    "                    continue\n",
    "\n",
    "                X_eeg_s.append(Xeeg[keep])\n",
    "                X_emg_s.append(Xemg[keep])\n",
    "                X_et_s.append(Xet[keep])\n",
    "                y_action_s.append(ya[keep])\n",
    "                y_task_s.append(yt[keep])\n",
    "\n",
    "            if not X_eeg_s:\n",
    "                continue\n",
    "\n",
    "            Xeeg = np.concatenate(X_eeg_s, axis=0).astype(np.float32)\n",
    "            Xemg = np.concatenate(X_emg_s, axis=0).astype(np.float32)\n",
    "            Xet  = np.concatenate(X_et_s,  axis=0).astype(np.float32)\n",
    "            ya   = np.concatenate(y_action_s, axis=0).astype(np.int64)\n",
    "            yt   = np.concatenate(y_task_s,   axis=0).astype(np.int64)\n",
    "\n",
    "            X_eeg_list.append(Xeeg)\n",
    "            X_emg_list.append(Xemg)\n",
    "            X_et_list.append(Xet)\n",
    "            y_action_list.append(ya)\n",
    "            y_task_list.append(yt)\n",
    "\n",
    "            # If features exist for this split, they MUST align with split windows count\n",
    "            if X_psd_split is not None and X_emg_split is not None:\n",
    "                if X_psd_split.shape[0] != Xeeg.shape[0] or X_emg_split.shape[0] != Xeeg.shape[0]:\n",
    "                    print(f\"[WARN] Feature mismatch fold{self.fold_id} {split}: \"\n",
    "                          f\"features N={X_psd_split.shape[0]} but windows N={Xeeg.shape[0]} -> skipping features.\")\n",
    "                else:\n",
    "                    X_psd_list.append(X_psd_split)\n",
    "                    X_emgfeat_list.append(X_emg_split)\n",
    "                    self.has_features = True\n",
    "\n",
    "        if not X_eeg_list:\n",
    "            raise RuntimeError(f\"No data found in fold={fold_id} splits={splits} (ssl_mode={ssl_mode}).\")\n",
    "\n",
    "        self.X_eeg = np.concatenate(X_eeg_list, axis=0)\n",
    "        self.X_emg = np.concatenate(X_emg_list, axis=0)\n",
    "        self.X_et  = np.concatenate(X_et_list,  axis=0)\n",
    "        self.y_action = np.concatenate(y_action_list, axis=0)\n",
    "        self.y_task   = np.concatenate(y_task_list,   axis=0)\n",
    "\n",
    "        if max_windows is not None and self.X_eeg.shape[0] > max_windows:\n",
    "            rng = np.random.RandomState(CFG.SEED)\n",
    "            idx = rng.choice(self.X_eeg.shape[0], size=max_windows, replace=False)\n",
    "            self.X_eeg = self.X_eeg[idx]\n",
    "            self.X_emg = self.X_emg[idx]\n",
    "            self.X_et  = self.X_et[idx]\n",
    "            self.y_action = self.y_action[idx]\n",
    "            self.y_task   = self.y_task[idx]\n",
    "            if self.has_features and X_psd_list and X_emgfeat_list:\n",
    "                # If we subsample, subsample features too\n",
    "                Xpsd_all = np.concatenate(X_psd_list, axis=0)\n",
    "                Xemg_all = np.concatenate(X_emgfeat_list, axis=0)\n",
    "                self.X_psd = Xpsd_all[idx]\n",
    "                self.X_emgfeat = Xemg_all[idx]\n",
    "            else:\n",
    "                self.has_features = False\n",
    "\n",
    "        else:\n",
    "            if self.has_features and X_psd_list and X_emgfeat_list:\n",
    "                self.X_psd = np.concatenate(X_psd_list, axis=0).astype(np.float32)\n",
    "                self.X_emgfeat = np.concatenate(X_emgfeat_list, axis=0).astype(np.float32)\n",
    "                if self.X_psd.shape[0] != self.X_eeg.shape[0]:\n",
    "                    print(\"[WARN] After concat, features N mismatch -> disabling features.\")\n",
    "                    self.has_features = False\n",
    "\n",
    "        self.eeg_ch = self.X_eeg.shape[-1]\n",
    "        self.emg_ch = self.X_emg.shape[-1]\n",
    "        self.et_ch  = self.X_et.shape[-1]\n",
    "\n",
    "        # Fixed mapping to keep inference stable\n",
    "        self.task2idx = {t: i for i, t in enumerate(CFG.TASK_CODES)}\n",
    "        self.num_task_classes = len(self.task2idx)\n",
    "\n",
    "        self.eeg_psd_dim = int(self.X_psd.shape[1]) if self.has_features else 0\n",
    "        self.emg_feat_dim = int(self.X_emgfeat.shape[1]) if self.has_features else 0\n",
    "\n",
    "        print(f\"[AllSplitsShardDataset] fold={fold_id} splits={splits} ssl_mode={ssl_mode}\")\n",
    "        print(f\"  N={len(self)} shapes: EEG={self.X_eeg.shape} EMG={self.X_emg.shape} ET={self.X_et.shape}\")\n",
    "        if self.has_features:\n",
    "            print(f\"  features: PSD={self.X_psd.shape} EMGfeat={self.X_emgfeat.shape}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.X_eeg.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x_eeg = torch.from_numpy(self.X_eeg[idx]).float()\n",
    "        x_emg = torch.from_numpy(self.X_emg[idx]).float()\n",
    "        x_et  = torch.from_numpy(self.X_et[idx]).float()\n",
    "\n",
    "        ya = int(self.y_action[idx])\n",
    "        yt_raw = int(self.y_task[idx])\n",
    "        action_label = 1 if ya == 1 else 0\n",
    "        task_label = self.task2idx.get(yt_raw, 0)\n",
    "\n",
    "        sample = {\n",
    "            \"eeg\": x_eeg,\n",
    "            \"emg\": x_emg,\n",
    "            \"et\":  x_et,\n",
    "            \"action\": torch.tensor(action_label, dtype=torch.long),\n",
    "            \"task\": torch.tensor(task_label, dtype=torch.long),\n",
    "            \"y_task_raw\": torch.tensor(yt_raw, dtype=torch.long),\n",
    "        }\n",
    "        if self.has_features:\n",
    "            sample[\"eeg_psd\"] = torch.from_numpy(self.X_psd[idx]).float()\n",
    "            sample[\"emg_feat\"] = torch.from_numpy(self.X_emgfeat[idx]).float()\n",
    "        return sample\n",
    "\n",
    "\n",
    "def make_loader(ds: Dataset, batch: int, shuffle: bool) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        ds, batch_size=batch, shuffle=shuffle,\n",
    "        num_workers=CFG.NUM_WORKERS, pin_memory=True, drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- MODEL (same spirit as your current) ----------------\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 4000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:, :T]\n",
    "\n",
    "\n",
    "class EEGTCNGRUEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        h = d_model\n",
    "        self.conv1 = nn.Conv1d(in_ch, h, 5, padding=2, dilation=1)\n",
    "        self.bn1 = nn.BatchNorm1d(h)\n",
    "        self.conv2 = nn.Conv1d(h, h, 5, padding=4, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(h)\n",
    "        self.conv3 = nn.Conv1d(h, h, 5, padding=8, dilation=4)\n",
    "        self.bn3 = nn.BatchNorm1d(h)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.act = nn.ReLU()\n",
    "        self.gru = nn.GRU(h, h // 2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(h, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        res = x\n",
    "        x = self.act(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.act(x + res)\n",
    "        x = self.drop(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.gru(x)\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class EMGTCNGRUEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        h = d_model\n",
    "        self.conv1 = nn.Conv1d(in_ch, h, 7, padding=3, dilation=1)\n",
    "        self.bn1 = nn.BatchNorm1d(h)\n",
    "        self.conv2 = nn.Conv1d(h, h, 7, padding=6, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(h)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.act = nn.ReLU()\n",
    "        self.gru = nn.GRU(h, h // 2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(h, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        res = self.act(self.bn1(self.conv1(x)))\n",
    "        x = self.act(self.bn2(self.conv2(res)))\n",
    "        x = self.drop(x + res)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.gru(x)\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class EyeTinyGRUEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(in_ch, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "        self.gru = nn.GRU(d_model, d_model // 2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.mlp(x)\n",
    "        x, _ = self.gru(x)\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class GatedSelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.n1 = nn.LayerNorm(d_model)\n",
    "        self.n2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, g: torch.Tensor) -> torch.Tensor:\n",
    "        q = x\n",
    "        k = x * g\n",
    "        v = x * g\n",
    "        y, _ = self.mha(q, k, v, need_weights=False)\n",
    "        x = self.n1(x + self.drop(y))\n",
    "        x = self.n2(x + self.drop(self.ffn(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GatedCrossModalEncoder(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, n_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.pe = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([GatedSelfAttentionBlock(d_model, n_heads, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, gates: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pe(tokens)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, gates)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TriModalSafetyTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eeg_ch: int, emg_ch: int, et_ch: int,\n",
    "        num_task_classes: int,\n",
    "        d_model: int, dropout: float,\n",
    "        use_eeg_psd: bool, use_emg_feat: bool,\n",
    "        eeg_psd_dim: int, emg_feat_dim: int,\n",
    "        eeg_psd_mean: Optional[torch.Tensor], eeg_psd_std: Optional[torch.Tensor],\n",
    "        emg_feat_mean: Optional[torch.Tensor], emg_feat_std: Optional[torch.Tensor],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_eeg_psd = use_eeg_psd and (eeg_psd_dim > 0)\n",
    "        self.use_emg_feat = use_emg_feat and (emg_feat_dim > 0)\n",
    "\n",
    "        self.eeg_enc = EEGTCNGRUEncoder(eeg_ch, d_model, dropout)\n",
    "        self.emg_enc = EMGTCNGRUEncoder(emg_ch, d_model, dropout)\n",
    "        self.et_enc  = EyeTinyGRUEncoder(et_ch, d_model, dropout)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.fuse = GatedCrossModalEncoder(d_model, CFG.N_HEADS_FUSE, CFG.N_LAYERS_FUSE, dropout)\n",
    "\n",
    "        self.gate_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model, d_model * 3),\n",
    "        )\n",
    "\n",
    "        if self.use_eeg_psd:\n",
    "            self.eeg_psd_proj = nn.Sequential(nn.Linear(eeg_psd_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "            self.register_buffer(\"eeg_psd_mean\", (eeg_psd_mean if eeg_psd_mean is not None else torch.zeros(1, eeg_psd_dim)).view(1, -1))\n",
    "            self.register_buffer(\"eeg_psd_std\",  (eeg_psd_std  if eeg_psd_std  is not None else torch.ones(1, eeg_psd_dim)).view(1, -1))\n",
    "        if self.use_emg_feat:\n",
    "            self.emg_feat_proj = nn.Sequential(nn.Linear(emg_feat_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "            self.register_buffer(\"emg_feat_mean\", (emg_feat_mean if emg_feat_mean is not None else torch.zeros(1, emg_feat_dim)).view(1, -1))\n",
    "            self.register_buffer(\"emg_feat_std\",  (emg_feat_std  if emg_feat_std  is not None else torch.ones(1, emg_feat_dim)).view(1, -1))\n",
    "\n",
    "        self.action_head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model), nn.Linear(d_model, d_model), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model, 2)\n",
    "        )\n",
    "        self.task_head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model), nn.Linear(d_model, d_model), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model, num_task_classes)\n",
    "        )\n",
    "\n",
    "        # SSL decoders + cross-modal heads\n",
    "        self.dec_eeg = nn.Linear(d_model, eeg_ch)\n",
    "        self.dec_emg = nn.Linear(d_model, emg_ch)\n",
    "        self.dec_et  = nn.Linear(d_model, et_ch)\n",
    "\n",
    "        self.cross_eeg2emg = nn.Linear(d_model, d_model)\n",
    "        self.cross_eeg2et  = nn.Linear(d_model, d_model)\n",
    "        self.cross_emg2eeg = nn.Linear(d_model, d_model)\n",
    "        self.cross_et2eeg  = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward_backbone(self, x_eeg, x_emg, x_et, eeg_psd=None, emg_feat=None):\n",
    "        z_eeg = self.eeg_enc(x_eeg)\n",
    "        z_emg = self.emg_enc(x_emg)\n",
    "        z_et  = self.et_enc(x_et)\n",
    "\n",
    "        if CFG.POOL_STRIDE > 1:\n",
    "            s = CFG.POOL_STRIDE\n",
    "            z_eeg = z_eeg[:, ::s, :]\n",
    "            z_emg = z_emg[:, ::s, :]\n",
    "            z_et  = z_et[:,  ::s, :]\n",
    "\n",
    "        B = z_eeg.size(0)\n",
    "        Te, Tm, Tt = z_eeg.size(1), z_emg.size(1), z_et.size(1)\n",
    "\n",
    "        p_eeg = z_eeg.mean(1)\n",
    "        p_emg = z_emg.mean(1)\n",
    "        p_et  = z_et.mean(1)\n",
    "\n",
    "        gates_logits = self.gate_mlp(torch.cat([p_eeg, p_emg, p_et], dim=-1)).view(B, 3, self.d_model)\n",
    "        gates = torch.softmax(gates_logits, dim=1)  # (B,3,D)\n",
    "\n",
    "        g_eeg = gates[:, 0, :].unsqueeze(1).expand(-1, Te, -1)\n",
    "        g_emg = gates[:, 1, :].unsqueeze(1).expand(-1, Tm, -1)\n",
    "        g_et  = gates[:, 2, :].unsqueeze(1).expand(-1, Tt, -1)\n",
    "\n",
    "        z_cat = torch.cat([z_eeg, z_emg, z_et], dim=1)\n",
    "        cls = self.cls_token.expand(B, 1, self.d_model)\n",
    "        tokens = torch.cat([cls, z_cat], dim=1)\n",
    "\n",
    "        g_cls = torch.ones(B, 1, self.d_model, device=tokens.device)\n",
    "        g_tok = torch.cat([g_cls, torch.cat([g_eeg, g_emg, g_et], dim=1)], dim=1)\n",
    "\n",
    "        out = self.fuse(tokens, g_tok)\n",
    "\n",
    "        # slice back\n",
    "        e0, e1 = 1, 1 + Te\n",
    "        m0, m1 = e1, e1 + Tm\n",
    "        t0, t1 = m1, m1 + Tt\n",
    "        ze = out[:, e0:e1, :]\n",
    "        zm = out[:, m0:m1, :]\n",
    "        zt = out[:, t0:t1, :]\n",
    "\n",
    "        cls_eeg = ze.mean(1)\n",
    "        cls_emg = zm.mean(1)\n",
    "        cls_et  = zt.mean(1)\n",
    "\n",
    "        g_e = gates[:, 0, :]\n",
    "        g_m = gates[:, 1, :]\n",
    "        g_t = gates[:, 2, :]\n",
    "\n",
    "        z_cls = g_e * cls_eeg + g_m * cls_emg + g_t * cls_et\n",
    "\n",
    "        # Optional Phase 5.5 features\n",
    "        add_feats = []\n",
    "        if self.use_eeg_psd and eeg_psd is not None:\n",
    "            x = (eeg_psd - self.eeg_psd_mean) / (self.eeg_psd_std + 1e-6)\n",
    "            add_feats.append(self.eeg_psd_proj(x))\n",
    "        if self.use_emg_feat and emg_feat is not None:\n",
    "            x = (emg_feat - self.emg_feat_mean) / (self.emg_feat_std + 1e-6)\n",
    "            add_feats.append(self.emg_feat_proj(x))\n",
    "        if add_feats:\n",
    "            z_cls = z_cls + torch.stack(add_feats, dim=0).mean(0)\n",
    "\n",
    "        return ze, zm, zt, z_cls, gates, cls_eeg, cls_emg, cls_et\n",
    "\n",
    "    def forward_supervised(self, x_eeg, x_emg, x_et, eeg_psd=None, emg_feat=None):\n",
    "        _, _, _, z_cls, gates, _, _, _ = self.forward_backbone(x_eeg, x_emg, x_et, eeg_psd, emg_feat)\n",
    "        return self.action_head(z_cls), self.task_head(z_cls), gates\n",
    "\n",
    "    def forward_ssl(self, x_eeg, x_emg, x_et):\n",
    "        ze, zm, zt, z_cls, gates, ce, cm, ct = self.forward_backbone(x_eeg, x_emg, x_et, None, None)\n",
    "        return self.dec_eeg(ze), self.dec_emg(zm), self.dec_et(zt), z_cls, gates, ce, cm, ct\n",
    "\n",
    "\n",
    "# ---------------- EMA ----------------\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model: nn.Module, decay: float):\n",
    "        self.decay = float(decay)\n",
    "        self.shadow = {}\n",
    "        for k, v in model.state_dict().items():\n",
    "            if torch.is_floating_point(v):\n",
    "                self.shadow[k] = v.detach().clone()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module):\n",
    "        msd = model.state_dict()\n",
    "        d = self.decay\n",
    "        for k, v in self.shadow.items():\n",
    "            nv = msd[k]\n",
    "            if torch.is_floating_point(nv):\n",
    "                v.mul_(d).add_(nv.detach(), alpha=1.0 - d)\n",
    "\n",
    "    def copy_to(self, model: nn.Module):\n",
    "        msd = model.state_dict()\n",
    "        for k, v in self.shadow.items():\n",
    "            if k in msd and torch.is_floating_point(msd[k]):\n",
    "                msd[k].copy_(v)\n",
    "\n",
    "\n",
    "# ---------------- SSL HELPERS ----------------\n",
    "\n",
    "def apply_ssl_mask(x: torch.Tensor, p: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    B, T, C = x.shape\n",
    "    mask = (torch.rand(B, T, 1, device=x.device) < p).float()\n",
    "    return x * (1.0 - mask), mask\n",
    "\n",
    "def apply_modality_dropout(x: torch.Tensor, p: float) -> torch.Tensor:\n",
    "    if p <= 0:\n",
    "        return x\n",
    "    B = x.size(0)\n",
    "    m = (torch.rand(B, 1, 1, device=x.device) < p).float()\n",
    "    return x * (1.0 - m)\n",
    "\n",
    "def ssl_recon_loss(x_hat: torch.Tensor, x_true: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "    # align if pooled\n",
    "    Th = x_hat.size(1)\n",
    "    Tt = x_true.size(1)\n",
    "    if Th != Tt:\n",
    "        if Tt % Th == 0:\n",
    "            f = Tt // Th\n",
    "            x_true = x_true[:, ::f, :]\n",
    "            mask = mask[:, ::f, :]\n",
    "        else:\n",
    "            x_true = x_true.transpose(1,2)\n",
    "            x_true = F.interpolate(x_true, size=Th, mode=\"linear\", align_corners=False).transpose(1,2)\n",
    "            mask = mask.transpose(1,2)\n",
    "            mask = F.interpolate(mask, size=Th, mode=\"nearest\").transpose(1,2)\n",
    "    m = mask.expand_as(x_hat)\n",
    "    diff2 = (x_hat - x_true) ** 2\n",
    "    return (diff2 * m).sum() / (m.sum() + 1e-8)\n",
    "\n",
    "def contrastive_loss(z1: torch.Tensor, z2: torch.Tensor, temp: float) -> torch.Tensor:\n",
    "    if z1.size(0) < 2:\n",
    "        return torch.tensor(0.0, device=z1.device)\n",
    "    z1 = F.normalize(z1, dim=-1)\n",
    "    z2 = F.normalize(z2, dim=-1)\n",
    "    logits = (z1 @ z2.t()) / temp\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)\n",
    "    return 0.5 * (F.cross_entropy(logits, labels) + F.cross_entropy(logits.t(), labels))\n",
    "\n",
    "def xmod_loss(model: TriModalSafetyTransformer, ce, cm, ct) -> torch.Tensor:\n",
    "    # predict other modality CLS from each CLS (MSE)\n",
    "    te = ce.detach(); tm = cm.detach(); tt = ct.detach()\n",
    "    loss = 0.0\n",
    "    loss += F.mse_loss(model.cross_eeg2emg(ce), tm)\n",
    "    loss += F.mse_loss(model.cross_eeg2et(ce),  tt)\n",
    "    loss += F.mse_loss(model.cross_emg2eeg(cm), te)\n",
    "    loss += F.mse_loss(model.cross_et2eeg(ct),  te)\n",
    "    return loss / 4.0\n",
    "\n",
    "\n",
    "# ---------------- TRAINING: SSL ----------------\n",
    "\n",
    "def pretrain_ssl(fold_id: int, eeg_ch: int, emg_ch: int, et_ch: int) -> Dict[str, torch.Tensor]:\n",
    "    print(\"\\n================ Stage 1: SSL pretraining (final) ================\")\n",
    "    fold_dir = CFG.DATASET_DIR / f\"{CFG.SSL_PREFIX}_fold{fold_id}\"\n",
    "    ssl_ds = AllSplitsShardDataset(\n",
    "        fold_dir=fold_dir, fold_id=fold_id, splits=[\"train\",\"val\",\"test\"],\n",
    "        ssl_mode=True, max_windows=CFG.SSL_MAX_WINDOWS, attach_features=False\n",
    "    )\n",
    "    loader = make_loader(ssl_ds, CFG.SSL_BATCH, shuffle=True)\n",
    "\n",
    "    dummy_task_classes = len(CFG.TASK_CODES)\n",
    "    model = TriModalSafetyTransformer(\n",
    "        eeg_ch, emg_ch, et_ch, dummy_task_classes,\n",
    "        CFG.D_MODEL, CFG.DROPOUT,\n",
    "        use_eeg_psd=False, use_emg_feat=False,\n",
    "        eeg_psd_dim=0, emg_feat_dim=0,\n",
    "        eeg_psd_mean=None, eeg_psd_std=None,\n",
    "        emg_feat_mean=None, emg_feat_std=None\n",
    "    ).to(CFG.DEVICE)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=CFG.SSL_LR, weight_decay=CFG.WEIGHT_DECAY)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(CFG.USE_AMP and CFG.DEVICE.startswith(\"cuda\")))\n",
    "\n",
    "    for ep in range(1, CFG.SSL_EPOCHS + 1):\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "        for batch in loader:\n",
    "            x_eeg = batch[\"eeg\"].to(CFG.DEVICE)\n",
    "            x_emg = batch[\"emg\"].to(CFG.DEVICE)\n",
    "            x_et  = batch[\"et\"].to(CFG.DEVICE)\n",
    "\n",
    "            x1_eeg, m1_eeg = apply_ssl_mask(x_eeg, CFG.SSL_MASK_PROB)\n",
    "            x1_emg, m1_emg = apply_ssl_mask(x_emg, CFG.SSL_MASK_PROB)\n",
    "            x1_et,  m1_et  = apply_ssl_mask(x_et,  CFG.SSL_MASK_PROB)\n",
    "\n",
    "            x2_eeg, _ = apply_ssl_mask(x_eeg, CFG.SSL_MASK_PROB)\n",
    "            x2_emg, _ = apply_ssl_mask(x_emg, CFG.SSL_MASK_PROB)\n",
    "            x2_et,  _ = apply_ssl_mask(x_et,  CFG.SSL_MASK_PROB)\n",
    "\n",
    "            x2_eeg = apply_modality_dropout(x2_eeg, CFG.SSL_MODAL_DROPOUT)\n",
    "            x2_emg = apply_modality_dropout(x2_emg, CFG.SSL_MODAL_DROPOUT)\n",
    "            x2_et  = apply_modality_dropout(x2_et,  CFG.SSL_MODAL_DROPOUT)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=scaler.is_enabled()):\n",
    "                xh_eeg, xh_emg, xh_et, z1, gates, ce, cm, ct = model.forward_ssl(x1_eeg, x1_emg, x1_et)\n",
    "                _, _, _, z2, _, _, _, _ = model.forward_backbone(x2_eeg, x2_emg, x2_et, None, None)\n",
    "\n",
    "                # upweight EEG+EMG recon\n",
    "                loss_mask = (\n",
    "                    1.6 * ssl_recon_loss(xh_eeg, x_eeg, m1_eeg)\n",
    "                    + 1.6 * ssl_recon_loss(xh_emg, x_emg, m1_emg)\n",
    "                    + 1.0 * ssl_recon_loss(xh_et,  x_et,  m1_et)\n",
    "                )\n",
    "                loss_ctr = contrastive_loss(z1, z2, CFG.SSL_TEMP)\n",
    "                loss_xm  = xmod_loss(model, ce, cm, ct)\n",
    "\n",
    "                loss = CFG.LAMBDA_MASK * loss_mask + CFG.LAMBDA_CONTRAST * loss_ctr + CFG.LAMBDA_XMOD * loss_xm\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.GRAD_CLIP)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "            tot += float(loss.item())\n",
    "            n += 1\n",
    "\n",
    "        print(f\"[SSL] ep {ep:02d}/{CFG.SSL_EPOCHS} loss={tot/max(1,n):.4f}\")\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "\n",
    "# ---------------- LOSS BUILDERS ----------------\n",
    "\n",
    "def build_action_weights(y_action: np.ndarray) -> torch.Tensor:\n",
    "    counts = np.bincount(y_action.astype(int), minlength=2).astype(np.float64)\n",
    "    w = len(y_action) / (2.0 * (counts + 1e-6))\n",
    "    return torch.tensor(w, dtype=torch.float32, device=CFG.DEVICE)\n",
    "\n",
    "def build_task_weights(y_task: np.ndarray, y_action: np.ndarray, ncls: int) -> torch.Tensor:\n",
    "    mask = (y_action.astype(int) == 1)\n",
    "    yt = y_task[mask].astype(int)\n",
    "    if yt.size == 0:\n",
    "        return torch.ones(ncls, dtype=torch.float32, device=CFG.DEVICE)\n",
    "    counts = np.bincount(yt, minlength=ncls).astype(np.float64)\n",
    "    w = len(yt) / (ncls * (counts + 1e-6))\n",
    "    return torch.tensor(w, dtype=torch.float32, device=CFG.DEVICE)\n",
    "\n",
    "\n",
    "# ---------------- METRICS + THRESHOLD ----------------\n",
    "\n",
    "def balanced_acc_binary(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = y_true.astype(int); y_pred = y_pred.astype(int)\n",
    "    tp = np.sum((y_true==1) & (y_pred==1))\n",
    "    tn = np.sum((y_true==0) & (y_pred==0))\n",
    "    fp = np.sum((y_true==0) & (y_pred==1))\n",
    "    fn = np.sum((y_true==1) & (y_pred==0))\n",
    "    tpr = tp / (tp + fn + 1e-8)\n",
    "    tnr = tn / (tn + fp + 1e-8)\n",
    "    return float(0.5*(tpr+tnr))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_on_loader(model: nn.Module, loader: DataLoader, base_threshold: float) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    ys_a, ps_a = [], []\n",
    "    ys_t, ps_t = [], []\n",
    "    for batch in loader:\n",
    "        x_eeg = batch[\"eeg\"].to(CFG.DEVICE)\n",
    "        x_emg = batch[\"emg\"].to(CFG.DEVICE)\n",
    "        x_et  = batch[\"et\"].to(CFG.DEVICE)\n",
    "        y_a   = batch[\"action\"].cpu().numpy()\n",
    "        y_t   = batch[\"task\"].cpu().numpy()\n",
    "\n",
    "        eeg_psd = batch.get(\"eeg_psd\")\n",
    "        emg_feat = batch.get(\"emg_feat\")\n",
    "        if eeg_psd is not None: eeg_psd = eeg_psd.to(CFG.DEVICE)\n",
    "        if emg_feat is not None: emg_feat = emg_feat.to(CFG.DEVICE)\n",
    "\n",
    "        logits_a, logits_t, _ = model.forward_supervised(x_eeg, x_emg, x_et, eeg_psd=eeg_psd, emg_feat=emg_feat)\n",
    "        p_act = torch.softmax(logits_a, dim=1)[:,1].detach().cpu().numpy()\n",
    "        pred_a = (p_act >= base_threshold).astype(int)\n",
    "\n",
    "        # task pred (force rest if no-move)\n",
    "        lt = logits_t.detach().cpu().numpy()\n",
    "        pred_t = lt.argmax(axis=1).astype(int)\n",
    "        pred_t[pred_a == 0] = 0\n",
    "\n",
    "        ys_a.append(y_a); ps_a.append(pred_a)\n",
    "        ys_t.append(y_t); ps_t.append(pred_t)\n",
    "\n",
    "    yA = np.concatenate(ys_a); pA = np.concatenate(ps_a)\n",
    "    yT = np.concatenate(ys_t); pT = np.concatenate(ps_t)\n",
    "\n",
    "    a_ba = balanced_acc_binary(yA, pA)\n",
    "\n",
    "    # task balanced acc computed on ACTION GT only (more meaningful)\n",
    "    mask = (yA == 1)\n",
    "    if mask.any():\n",
    "        # balanced acc for multiclass (manual)\n",
    "        yt = yT[mask]; pt = pT[mask]\n",
    "        cls = np.unique(yt)\n",
    "        recs = []\n",
    "        for c in cls:\n",
    "            den = np.sum(yt == c)\n",
    "            recs.append(np.sum((yt==c) & (pt==c)) / (den + 1e-8))\n",
    "        t_ba = float(np.mean(recs)) if recs else 0.0\n",
    "    else:\n",
    "        t_ba = 0.0\n",
    "\n",
    "    return {\"action_bal_acc\": a_ba, \"task_bal_acc_action_only\": t_ba}\n",
    "\n",
    "@torch.no_grad()\n",
    "def tune_threshold(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    probs, ys = [], []\n",
    "    for batch in loader:\n",
    "        x_eeg = batch[\"eeg\"].to(CFG.DEVICE)\n",
    "        x_emg = batch[\"emg\"].to(CFG.DEVICE)\n",
    "        x_et  = batch[\"et\"].to(CFG.DEVICE)\n",
    "        y_a   = batch[\"action\"].cpu().numpy()\n",
    "\n",
    "        eeg_psd = batch.get(\"eeg_psd\")\n",
    "        emg_feat = batch.get(\"emg_feat\")\n",
    "        if eeg_psd is not None: eeg_psd = eeg_psd.to(CFG.DEVICE)\n",
    "        if emg_feat is not None: emg_feat = emg_feat.to(CFG.DEVICE)\n",
    "\n",
    "        logits_a, _, _ = model.forward_supervised(x_eeg, x_emg, x_et, eeg_psd=eeg_psd, emg_feat=emg_feat)\n",
    "        p = torch.softmax(logits_a, dim=1)[:,1].cpu().numpy()\n",
    "        probs.append(p); ys.append(y_a)\n",
    "\n",
    "    p = np.concatenate(probs); y = np.concatenate(ys)\n",
    "    best_t, best_ba = 0.5, -1.0\n",
    "    for t in CFG.THRESH_GRID:\n",
    "        pred = (p >= t).astype(int)\n",
    "        ba = balanced_acc_binary(y, pred)\n",
    "        if ba > best_ba:\n",
    "            best_ba, best_t = ba, float(t)\n",
    "    print(f\"[threshold] best τ={best_t:.2f} val_action_bal_acc={best_ba:.3f}\")\n",
    "    return best_t\n",
    "\n",
    "\n",
    "# ---------------- LR SCHEDULER (warmup + cosine) ----------------\n",
    "\n",
    "class WarmupCosine:\n",
    "    def __init__(self, optimizer, warmup_steps: int, total_steps: int, min_lr_scale: float = 0.05):\n",
    "        self.opt = optimizer\n",
    "        self.warmup = max(1, warmup_steps)\n",
    "        self.total = max(self.warmup + 1, total_steps)\n",
    "        self.min_lr_scale = float(min_lr_scale)\n",
    "        self.step_i = 0\n",
    "        self.base_lrs = [g[\"lr\"] for g in optimizer.param_groups]\n",
    "\n",
    "    def step(self):\n",
    "        self.step_i += 1\n",
    "        if self.step_i <= self.warmup:\n",
    "            scale = self.step_i / self.warmup\n",
    "        else:\n",
    "            t = (self.step_i - self.warmup) / (self.total - self.warmup)\n",
    "            scale = self.min_lr_scale + 0.5 * (1.0 - self.min_lr_scale) * (1.0 + math.cos(math.pi * t))\n",
    "        for lr0, g in zip(self.base_lrs, self.opt.param_groups):\n",
    "            g[\"lr\"] = lr0 * scale\n",
    "\n",
    "\n",
    "# ---------------- FINAL TRAIN (ONE MODEL) ----------------\n",
    "\n",
    "def train_final_allsubjects(fold_id: int, out_dir: Path) -> Tuple[Path, Path]:\n",
    "    print(\"\\n================ FINAL: Train ONE all-subjects model ================\")\n",
    "    print(\"Fold used:\", fold_id)\n",
    "\n",
    "    fold_bal = CFG.DATASET_DIR / f\"{CFG.BAL_PREFIX}_fold{fold_id}\"\n",
    "    ds_all = AllSplitsShardDataset(\n",
    "        fold_dir=fold_bal, fold_id=fold_id, splits=[\"train\",\"val\",\"test\"],\n",
    "        ssl_mode=False, max_windows=None, attach_features=True\n",
    "    )\n",
    "    eeg_ch, emg_ch, et_ch = ds_all.eeg_ch, ds_all.emg_ch, ds_all.et_ch\n",
    "\n",
    "    # Build train/val split (stratify by task)\n",
    "    y_task = ds_all.y_task.copy()\n",
    "    tr_idx, va_idx = stratified_split_indices(y_task, CFG.VAL_FRAC, CFG.SEED)\n",
    "    ds_tr = Subset(ds_all, tr_idx.tolist())\n",
    "    ds_va = Subset(ds_all, va_idx.tolist())\n",
    "\n",
    "    tr_loader = make_loader(ds_tr, CFG.SUP_BATCH, shuffle=True)\n",
    "    va_loader = make_loader(ds_va, CFG.SUP_BATCH, shuffle=False)\n",
    "\n",
    "    # Features stats from TRAIN only\n",
    "    use_feats = ds_all.has_features and CFG.USE_EEG_PSD_FEATURES and CFG.USE_EMG_FEATURES\n",
    "    eeg_psd_dim = ds_all.eeg_psd_dim if use_feats else 0\n",
    "    emg_feat_dim = ds_all.emg_feat_dim if use_feats else 0\n",
    "\n",
    "    eeg_psd_mean_t = eeg_psd_std_t = None\n",
    "    emg_feat_mean_t = emg_feat_std_t = None\n",
    "\n",
    "    if use_feats:\n",
    "        Xpsd_tr = ds_all.X_psd[tr_idx].astype(np.float32)\n",
    "        Xemg_tr = ds_all.X_emgfeat[tr_idx].astype(np.float32)\n",
    "        eeg_psd_mean_t = torch.from_numpy(Xpsd_tr.mean(0)).float().to(CFG.DEVICE)\n",
    "        eeg_psd_std_t  = torch.from_numpy(Xpsd_tr.std(0) + 1e-6).float().to(CFG.DEVICE)\n",
    "        emg_feat_mean_t = torch.from_numpy(Xemg_tr.mean(0)).float().to(CFG.DEVICE)\n",
    "        emg_feat_std_t  = torch.from_numpy(Xemg_tr.std(0) + 1e-6).float().to(CFG.DEVICE)\n",
    "\n",
    "    # Build model\n",
    "    model = TriModalSafetyTransformer(\n",
    "        eeg_ch, emg_ch, et_ch, num_task_classes=len(CFG.TASK_CODES),\n",
    "        d_model=CFG.D_MODEL, dropout=CFG.DROPOUT,\n",
    "        use_eeg_psd=use_feats, use_emg_feat=use_feats,\n",
    "        eeg_psd_dim=eeg_psd_dim, emg_feat_dim=emg_feat_dim,\n",
    "        eeg_psd_mean=eeg_psd_mean_t, eeg_psd_std=eeg_psd_std_t,\n",
    "        emg_feat_mean=emg_feat_mean_t, emg_feat_std=emg_feat_std_t,\n",
    "    ).to(CFG.DEVICE)\n",
    "\n",
    "    # Optional SSL init\n",
    "    if CFG.USE_SSL:\n",
    "        print(\"[FINAL] SSL pretraining enabled…\")\n",
    "        base_state = pretrain_ssl(fold_id, eeg_ch, emg_ch, et_ch)\n",
    "        miss, unexp = model.load_state_dict(base_state, strict=False)\n",
    "        print(f\"[FINAL] Loaded SSL backbone. Missing={len(miss)} Unexpected={len(unexp)}\")\n",
    "    else:\n",
    "        print(\"[FINAL] SSL disabled → random init.\")\n",
    "\n",
    "    # Freeze backbone warm-start\n",
    "    def set_backbone_trainable(flag: bool):\n",
    "        for name, p in model.named_parameters():\n",
    "            if name.startswith(\"action_head\") or name.startswith(\"task_head\"):\n",
    "                p.requires_grad = True\n",
    "            else:\n",
    "                p.requires_grad = flag\n",
    "\n",
    "    # Loss weights from TRAIN subset (using underlying arrays)\n",
    "    y_action_tr = ds_all.y_action[tr_idx]\n",
    "    y_task_tr   = np.array([ds_all.task2idx.get(int(t), 0) for t in ds_all.y_task[tr_idx]], dtype=np.int64)\n",
    "\n",
    "    w_action = build_action_weights(y_action_tr)\n",
    "    w_task   = build_task_weights(y_task_tr, y_action_tr, ncls=len(CFG.TASK_CODES))\n",
    "\n",
    "    crit_action = nn.CrossEntropyLoss(weight=w_action)\n",
    "    crit_task   = nn.CrossEntropyLoss(weight=w_task)\n",
    "\n",
    "    head_params, backbone_params = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if n.startswith(\"action_head.\") or n.startswith(\"task_head.\"):\n",
    "            head_params.append(p)\n",
    "        else:\n",
    "            backbone_params.append(p)\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": CFG.SUP_LR * CFG.BACKBONE_LR_SCALE},\n",
    "            {\"params\": head_params,     \"lr\": CFG.SUP_LR},\n",
    "        ],\n",
    "        weight_decay=CFG.WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "    # Steps for scheduler\n",
    "    steps_per_epoch = max(1, len(tr_loader))\n",
    "    total_steps = CFG.SUP_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(0.08 * total_steps)\n",
    "    sched = WarmupCosine(opt, warmup_steps=warmup_steps, total_steps=total_steps, min_lr_scale=0.08)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(CFG.USE_AMP and CFG.DEVICE.startswith(\"cuda\")))\n",
    "    ema = EMA(model, CFG.EMA_DECAY) if CFG.USE_EMA else None\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_state = None\n",
    "    best_tau = 0.5\n",
    "\n",
    "    global_step = 0\n",
    "    for ep in range(1, CFG.SUP_EPOCHS + 1):\n",
    "        model.train()\n",
    "\n",
    "        # backbone freeze warm-start\n",
    "        if ep <= CFG.FREEZE_BACKBONE_EPOCHS:\n",
    "            set_backbone_trainable(False)\n",
    "        else:\n",
    "            set_backbone_trainable(True)\n",
    "\n",
    "        t0 = time.time()\n",
    "        run_loss = 0.0\n",
    "        n_samples = 0\n",
    "\n",
    "        for batch in tr_loader:\n",
    "            global_step += 1\n",
    "\n",
    "            x_eeg = batch[\"eeg\"].to(CFG.DEVICE)\n",
    "            x_emg = batch[\"emg\"].to(CFG.DEVICE)\n",
    "            x_et  = batch[\"et\"].to(CFG.DEVICE)\n",
    "            y_a   = batch[\"action\"].to(CFG.DEVICE)\n",
    "            y_t   = batch[\"task\"].to(CFG.DEVICE)\n",
    "\n",
    "            eeg_psd = batch.get(\"eeg_psd\")\n",
    "            emg_feat = batch.get(\"emg_feat\")\n",
    "            if eeg_psd is not None: eeg_psd = eeg_psd.to(CFG.DEVICE)\n",
    "            if emg_feat is not None: emg_feat = emg_feat.to(CFG.DEVICE)\n",
    "\n",
    "            # supervised ET dropout\n",
    "            if CFG.SUP_ET_DROPOUT > 0:\n",
    "                x_et = apply_modality_dropout(x_et, CFG.SUP_ET_DROPOUT)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=scaler.is_enabled()):\n",
    "                la, lt, _ = model.forward_supervised(x_eeg, x_emg, x_et, eeg_psd=eeg_psd, emg_feat=emg_feat)\n",
    "                loss_a = crit_action(la, y_a)\n",
    "\n",
    "                mask = (y_a == 1)\n",
    "                if mask.any():\n",
    "                    loss_t = crit_task(lt[mask], y_t[mask])\n",
    "                else:\n",
    "                    loss_t = torch.tensor(0.0, device=CFG.DEVICE)\n",
    "\n",
    "                loss = CFG.ALPHA_ACTION * loss_a + CFG.BETA_TASK * loss_t\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.GRAD_CLIP)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            sched.step()\n",
    "\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            B = int(y_a.size(0))\n",
    "            run_loss += float(loss.item()) * B\n",
    "            n_samples += B\n",
    "\n",
    "        # Validate using EMA weights if enabled\n",
    "        val_model = model\n",
    "        if ema is not None:\n",
    "            tmp = TriModalSafetyTransformer(\n",
    "                ds_all.eeg_ch, ds_all.emg_ch, ds_all.et_ch, len(CFG.TASK_CODES),\n",
    "                CFG.D_MODEL, CFG.DROPOUT,\n",
    "                use_eeg_psd=use_feats, use_emg_feat=use_feats,\n",
    "                eeg_psd_dim=eeg_psd_dim, emg_feat_dim=emg_feat_dim,\n",
    "                eeg_psd_mean=eeg_psd_mean_t, eeg_psd_std=eeg_psd_std_t,\n",
    "                emg_feat_mean=emg_feat_mean_t, emg_feat_std=emg_feat_std_t,\n",
    "            ).to(CFG.DEVICE)\n",
    "            tmp.load_state_dict(model.state_dict(), strict=True)\n",
    "            ema.copy_to(tmp)\n",
    "            val_model = tmp\n",
    "\n",
    "        # quick threshold=0.5 for metric scoring\n",
    "        metrics = eval_on_loader(val_model, va_loader, base_threshold=0.5)\n",
    "        score = 0.35 * metrics[\"action_bal_acc\"] + 0.65 * metrics[\"task_bal_acc_action_only\"]\n",
    "\n",
    "        print(\n",
    "            f\"[FINAL] ep {ep:02d}/{CFG.SUP_EPOCHS} \"\n",
    "            f\"train_loss={run_loss/max(1,n_samples):.4f} \"\n",
    "            f\"val_action_BA={metrics['action_bal_acc']:.3f} \"\n",
    "            f\"val_task_BA(action)={metrics['task_bal_acc_action_only']:.3f} \"\n",
    "            f\"score={score:.3f} \"\n",
    "            f\"time={time.time()-t0:.1f}s\"\n",
    "        )\n",
    "\n",
    "        if score > best_score + 1e-4:\n",
    "            best_score = score\n",
    "            # tune threshold on best model snapshot\n",
    "            tau = tune_threshold(val_model, va_loader)\n",
    "            best_tau = float(tau)\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in val_model.state_dict().items()}\n",
    "\n",
    "    if best_state is None:\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_path = out_dir / f\"best_model_allsubjects_fold{fold_id}.pt\"\n",
    "    stats_path = out_dir / f\"stats_allsubjects_fold{fold_id}.json\"\n",
    "\n",
    "    torch.save(best_state, ckpt_path)\n",
    "\n",
    "    stats = {\n",
    "        \"fold_id_used\": int(fold_id),\n",
    "        \"base_threshold\": float(best_tau),\n",
    "        \"task2idx\": {str(k): int(v) for k, v in ds_all.task2idx.items()},\n",
    "        \"idx2task\": {str(v): int(k) for k, v in ds_all.task2idx.items()},\n",
    "        \"eeg_ch\": int(ds_all.eeg_ch),\n",
    "        \"emg_ch\": int(ds_all.emg_ch),\n",
    "        \"et_ch\": int(ds_all.et_ch),\n",
    "        \"use_features\": bool(use_feats),\n",
    "        \"eeg_psd_dim\": int(eeg_psd_dim),\n",
    "        \"emg_feat_dim\": int(emg_feat_dim),\n",
    "        \"cfg\": {\n",
    "            \"d_model\": CFG.D_MODEL,\n",
    "            \"dropout\": CFG.DROPOUT,\n",
    "            \"pool_stride\": CFG.POOL_STRIDE,\n",
    "            \"n_heads_fuse\": CFG.N_HEADS_FUSE,\n",
    "            \"n_layers_fuse\": CFG.N_LAYERS_FUSE,\n",
    "        }\n",
    "    }\n",
    "    if use_feats:\n",
    "        stats[\"eeg_psd_mean\"] = eeg_psd_mean_t.detach().cpu().numpy().tolist()\n",
    "        stats[\"eeg_psd_std\"]  = eeg_psd_std_t.detach().cpu().numpy().tolist()\n",
    "        stats[\"emg_feat_mean\"] = emg_feat_mean_t.detach().cpu().numpy().tolist()\n",
    "        stats[\"emg_feat_std\"]  = emg_feat_std_t.detach().cpu().numpy().tolist()\n",
    "\n",
    "    stats_path.write_text(json.dumps(stats, indent=2))\n",
    "    print(\"\\n[SAVED]\")\n",
    "    print(\"  ckpt :\", ckpt_path)\n",
    "    print(\"  stats:\", stats_path)\n",
    "    print(f\"  best τ={best_tau:.2f}\")\n",
    "\n",
    "    return ckpt_path, stats_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--fold\", type=int, default=-1, help=\"Which fold to use as the 'all-data' source (train+val+test).\")\n",
    "    ap.add_argument(\"--out\", type=str, default=str(CFG.DATASET_DIR / \"checkpoints_allsubjects\"),\n",
    "                    help=\"Output directory for final checkpoint + stats json.\")\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    folds = discover_folds(CFG.BAL_PREFIX)\n",
    "    if not folds:\n",
    "        raise SystemExit(f\"No balanced folds found under {CFG.DATASET_DIR} with prefix {CFG.BAL_PREFIX}_fold*\")\n",
    "\n",
    "    fold_id = args.fold\n",
    "    if fold_id < 0:\n",
    "        fold_id = folds[0]  # any fold works; union train+val+test covers all subjects\n",
    "    if fold_id not in folds:\n",
    "        raise SystemExit(f\"Requested fold={fold_id} not found. Available folds: {folds}\")\n",
    "\n",
    "    out_dir = Path(args.out)\n",
    "    train_final_allsubjects(fold_id=fold_id, out_dir=out_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
