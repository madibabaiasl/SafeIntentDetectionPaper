{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f63bd-7515-451a-a355-2f445ea38d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BioRob Phase-2 Labeler — HSMM (Single-Action)\n",
    "# =============================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse, re, glob, json, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "from scipy.stats import median_abs_deviation, norm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal as _sig\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========================== USER PATHS ===========================\n",
    "ROOT_DIR   = r\"/home/tsultan1/BioRob(Final)/Data\"\n",
    "SYNC_SUBPATH = r\"cleaned/synchronized_proper_lite_union_v3\"\n",
    "DEFAULT_SUBJECT_SYNC_DIR = Path(\n",
    "    r\"/home/tsultan1/BioRob(Final)/Data/Sub-23/cleaned/synchronized_proper_lite_union_v3\"\n",
    ")\n",
    "FILE_GLOB = \"*_synchronized_corrected.csv\"\n",
    "FS_HINT   = 250.0\n",
    "\n",
    "SAVE_PLOTS_STANDARD  = False\n",
    "SAVE_PLOTS_EXTENDED  = False\n",
    "ADD_SPECTROGRAM      = False\n",
    "\n",
    "FORCE_MODE = 'physical'   # 'physical'|'imagery'|None\n",
    "MODE_POLICY = 'auto'      # 'auto'|'filename'|'infer'\n",
    "USE_SKLEARN_GMM = False\n",
    "\n",
    "# =============================== BASE PARAMS =========================\n",
    "BASE = dict(\n",
    "    smooth_win_default = 75,     # ~300 ms @ 250 Hz\n",
    "    smooth_win_physical = 50,\n",
    "    smooth_win_imagery  = 125,\n",
    "\n",
    "    eye_valid_min   = 0.60,\n",
    "\n",
    "    target_dur_physical = (0.8, 8.0),\n",
    "    target_dur_imagery  = (0.5, 6.0),\n",
    "\n",
    "    prob_scale_frac = 0.25,\n",
    "\n",
    "    # boundary refiners (pre HSMM result)\n",
    "    phys_backseek_s   = 0.75,  phys_forward_s = 0.75,\n",
    "    phys_on_grad_thr  = 0.60,  phys_on_env_thr  = 0.30,\n",
    "    phys_off_env_thr  = 0.25,  phys_min_sustain_s = 0.10,\n",
    "\n",
    "    imag_backseek_s   = 1.00,  imag_forward_s = 0.75,\n",
    "    imag_on_slope_thr = -0.40, imag_on_eeg_thr = -0.20,\n",
    "    imag_off_abs_thr  = 0.20,  imag_min_sustain_s = 0.12,\n",
    ")\n",
    "\n",
    "MIN_BOUT_S = 0.20\n",
    "MAX_GAP_S  = 0.10\n",
    "\n",
    "# =================== SHIELDS & HARD CLAMPS ===================\n",
    "PRE_BASELINE_S      = 2.0\n",
    "POST_BASELINE_S     = 1.25\n",
    "\n",
    "ON_Z_K              = 2.1\n",
    "OFF_Z_K             = 1.8\n",
    "MIN_SUSTAIN_ON_S    = 0.18\n",
    "MIN_SUSTAIN_OFF_S   = 0.25\n",
    "BACKOFF_ON_S        = 0.12\n",
    "BACKOFF_OFF_S       = 0.06\n",
    "\n",
    "# ---- HARD RULE WINDOWS ----\n",
    "PRE_REST_MIN_S = 3.0     # earliest allowed end of pre-rest\n",
    "PRE_REST_MAX_S = 4.0     # latest  allowed end of pre-rest\n",
    "POST_REST_MIN_S = 1.0    # nominal min end-rest duration (can relax to 0.5s)\n",
    "POST_REST_MAX_S = 4.0    # max end-rest duration\n",
    "\n",
    "# ---- Tail quiet-window recovery (EMG-driven) ----\n",
    "TAIL_EXTEND_MAX_S        = 2.5   # allow extending up to this much after HSMM offset\n",
    "TAIL_QUIET_S             = 0.30  # quiet must persist this long\n",
    "TAIL_BACKOFF_S           = 0.06  # step back a hair before the quiet starts\n",
    "REST_K                   = 1.3   # rest envelope threshold = median + K*MAD (pre-rest baseline)\n",
    "GRAD_QUIET_THR           = 0.45  # EMG gradient (z) must be below this to call it quiet\n",
    "TAIL_OVERRIDE_MIN_REST_S = 0.5   # if action pushes near end, relax min tail-rest to 0.5s\n",
    "\n",
    "# =============================== HELPERS =============================\n",
    "def mad(x): \n",
    "    return 1.4826 * median_abs_deviation(x, nan_policy='omit')\n",
    "\n",
    "def robust_z(x):\n",
    "    x = np.asarray(x)\n",
    "    m = np.nanmedian(x)\n",
    "    s = mad(x)\n",
    "    return np.zeros_like(x) if (s < 1e-12 or not np.isfinite(s)) else (x - m)/s\n",
    "\n",
    "def rolling_mean(x, n):\n",
    "    if n <= 1: return np.asarray(x)\n",
    "    k = np.ones(int(n), float) / max(1, int(n))\n",
    "    return np.convolve(np.asarray(x), k, mode='same')\n",
    "\n",
    "def rolling_rms(x, fs, win_ms):\n",
    "    n = max(1, int(win_ms/1000*fs))\n",
    "    if n == 1: return np.abs(x)\n",
    "    ker = np.ones(n)/n\n",
    "    return np.sqrt(np.convolve(np.square(np.nan_to_num(x)), ker, 'same'))\n",
    "\n",
    "def median_fs(t):\n",
    "    dt = np.median(np.diff(t))\n",
    "    return (1.0/dt) if np.isfinite(dt) and dt > 0 else FS_HINT\n",
    "\n",
    "def _first_true_in_window(mask: np.ndarray, lo: int, hi: int) -> Optional[int]:\n",
    "    lo = max(0, lo); hi = min(len(mask)-1, hi)\n",
    "    idx = np.flatnonzero(mask[lo:hi+1])\n",
    "    return (lo + int(idx[0])) if idx.size else None\n",
    "\n",
    "def _last_true_in_window(mask: np.ndarray, lo: int, hi: int) -> Optional[int]:\n",
    "    lo = max(0, lo); hi = min(len(mask)-1, hi)\n",
    "    idx = np.flatnonzero(mask[lo:hi+1])\n",
    "    return (lo + int(idx[-1])) if idx.size else None\n",
    "\n",
    "import re as _re\n",
    "def canonicalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mapping = {}\n",
    "    for raw in df.columns:\n",
    "        s = str(raw).replace(\"\\ufeff\",\"\")\n",
    "        s = _re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        if s.lower() == \"timestamp_seconds\": mapping[raw]=\"Timestamp_seconds\"; continue\n",
    "        if s.lower() == \"timestamp_ms\":      mapping[raw]=\"Timestamp_ms\"; continue\n",
    "        if s.lower() == \"et_timesignal\":     mapping[raw]=\"ET_TimeSignal\"; continue\n",
    "        m = _re.match(r'(?i)^ch\\s*(\\d+)\\s*emg\\s*raw$', s)\n",
    "        if m: mapping[raw] = f\"EMG_Ch{int(m.group(1))}\"; continue\n",
    "        m = _re.match(r'(?i)^ch\\s*(\\d+)\\s*emg$', s)\n",
    "        if m: mapping[raw] = f\"EMG_Ch{int(m.group(1))}\"; continue\n",
    "        m = _re.match(r'(?i)^ch\\s*(\\d+)$', s)\n",
    "        if m:\n",
    "            ch = int(m.group(1))\n",
    "            if 1 <= ch <= 32:\n",
    "                mapping[raw] = f\"EEG_Ch{ch}\"; continue\n",
    "        if s.startswith(\"ET_\") or s.lower().startswith(\"et_\"):\n",
    "            name = s if s.startswith(\"ET_\") else (\"ET_\" + s[3:])\n",
    "            name = name.replace(\"GazeLeftX\",\"GazeLeftx\").replace(\"GazeLeftY\",\"GazeLefty\")\n",
    "            name = name.replace(\"GazeRightX\",\"GazeRightx\").replace(\"GazeRightY\",\"GazeRighty\")\n",
    "            mapping[raw] = name; continue\n",
    "        mapping[raw] = s\n",
    "    return df.rename(columns=mapping)\n",
    "\n",
    "# ======================= FEATURE EXTRACTION ==========================\n",
    "def _et_signal_audit(df: pd.DataFrame) -> dict:\n",
    "    groups = {\n",
    "        \"pupil\": [\"ET_PupilLeft\",\"ET_PupilRight\"],\n",
    "        \"gaze_xy\": [\"ET_GazeLeftx\",\"ET_GazeLefty\",\"ET_GazeRightx\",\"ET_GazeRighty\"],\n",
    "        \"valid\": [\"ET_ValidityLeftEye\",\"ET_ValidityRightEye\"],\n",
    "        \"imu\": [\"ET_GyroX\",\"ET_GyroY\",\"ET_GyroZ\",\"ET_AccX\",\"ET_AccY\",\"ET_AccZ\",\n",
    "                \"ET_HeadRotationPitch\",\"ET_HeadRotationYaw\",\"ET_HeadRotationRoll\"],\n",
    "        \"events\": [\"ET_Blink\",\"ET_Fixation\",\"ET_Worn\"],\n",
    "        \"fallback_axis\": [\"ET_Gaze3dOpticalAxisXLeft\",\"ET_Gaze3dOpticalAxisYLeft\",\"ET_Gaze3dOpticalAxisZLeft\"]\n",
    "    }\n",
    "    return {k: [c for c in v if c in df.columns] for k, v in groups.items()}\n",
    "\n",
    "def _eye_activity(df, fs):\n",
    "    if {'ET_GazeLeftx','ET_GazeLefty'}.issubset(df.columns):\n",
    "        gx = df['ET_GazeLeftx'].astype(float).ffill().bfill().to_numpy()\n",
    "        gy = df['ET_GazeLefty'].astype(float).ffill().bfill().to_numpy()\n",
    "        vx = np.diff(gx, prepend=gx[0]) * fs\n",
    "        vy = np.diff(gy, prepend=gy[0]) * fs\n",
    "        spd = np.sqrt(vx**2 + vy**2)\n",
    "        return robust_z(rolling_rms(spd, fs, 50))\n",
    "    cols = ['ET_Gaze3dOpticalAxisXLeft','ET_Gaze3dOpticalAxisYLeft','ET_Gaze3dOpticalAxisZLeft']\n",
    "    if set(cols).issubset(df.columns):\n",
    "        X = df[cols].astype(float).ffill().bfill().to_numpy()\n",
    "        nrm = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "        V = X / nrm\n",
    "        dots = np.clip(np.sum(V[1:] * V[:-1], axis=1), -1.0, 1.0)\n",
    "        dtheta = np.arccos(dots)\n",
    "        ang_spd = np.r_[0.0, dtheta * fs]\n",
    "        return robust_z(rolling_rms(ang_spd, fs, 50))\n",
    "    if 'ET_Blink' in df.columns:\n",
    "        b = df['ET_Blink'].astype(float).fillna(0.0).to_numpy()\n",
    "        feat = rolling_rms(np.diff(b, prepend=b[0]) * fs, fs, 100)\n",
    "        return robust_z(feat)\n",
    "    return np.zeros(len(df), float)\n",
    "\n",
    "def _eye_valid_rate(df) -> float:\n",
    "    if {'ET_ValidityLeftEye','ET_ValidityRightEye'}.issubset(df.columns):\n",
    "        vl = (df['ET_ValidityLeftEye'].values == 0)\n",
    "        vr = (df['ET_ValidityRightEye'].values == 0)\n",
    "        return float(np.mean(vl & vr))\n",
    "    return 0.4 if any(c.startswith('ET_') for c in df.columns) else 0.0\n",
    "\n",
    "def extract_features(df, fs):\n",
    "    t = df['Timestamp_seconds'].to_numpy()\n",
    "    nyq = fs/2\n",
    "\n",
    "    eeg_cols = [c for c in [f'EEG_Ch{i}' for i in range(1,9)] if c in df.columns]\n",
    "    if eeg_cols:\n",
    "        sos_mrcp  = butter(4, [0.05/nyq, 3.0/nyq], btype='band', output='sos')\n",
    "        sos_beta  = butter(4, [13/nyq, 30/nyq], btype='band', output='sos')\n",
    "        eeg_feats = []; eeg_slope_feats=[]\n",
    "        for ch in eeg_cols:\n",
    "            x = df[ch].astype(float).ffill().bfill().to_numpy()\n",
    "            mrcp = sosfiltfilt(sos_mrcp, x)\n",
    "            mrcp_slope = -np.gradient(mrcp, 1/fs)\n",
    "            eeg_slope_feats.append(robust_z(mrcp_slope))\n",
    "            beta = sosfiltfilt(sos_beta, x)\n",
    "            beta_power = rolling_rms(beta, fs, 200)\n",
    "            eeg_feats.append(0.7*eeg_slope_feats[-1] + 0.3*(-robust_z(beta_power)))\n",
    "        eeg = np.mean(eeg_feats, axis=0)\n",
    "        eeg_slope = np.mean(eeg_slope_feats, axis=0)\n",
    "    else:\n",
    "        eeg = eeg_slope = np.zeros_like(t)\n",
    "\n",
    "    emg_cols = [c for c in [f'EMG_Ch{i}' for i in range(1,5)] if c in df.columns]\n",
    "    if emg_cols:\n",
    "        envs = []; raws = []\n",
    "        for ch in emg_cols:\n",
    "            x = df[ch].astype(float).fillna(0.0).to_numpy()\n",
    "            raws.append(x); envs.append(robust_z(rolling_rms(x, fs, 50)))\n",
    "        emg = np.mean(envs, axis=0)\n",
    "        emg_raw_mean = np.mean(raws, axis=0)\n",
    "        emg_grad = robust_z(rolling_rms(np.gradient(emg_raw_mean, 1/fs), fs, 30))\n",
    "    else:\n",
    "        emg = emg_grad = np.zeros_like(t)\n",
    "\n",
    "    eye = _eye_activity(df, fs)\n",
    "    eye_valid = _eye_valid_rate(df)\n",
    "\n",
    "    def rel_from_signal(sig):\n",
    "        if sig.size == 0: return 0.0\n",
    "        spread = float(np.nanpercentile(sig,95) - np.nanpercentile(sig,50))\n",
    "        denom = mad(sig) + 1e-9\n",
    "        val = max(0.0, spread/denom)\n",
    "        return val if np.isfinite(val) else 0.0\n",
    "\n",
    "    R = dict(emg=rel_from_signal(emg),\n",
    "             eeg=rel_from_signal(eeg_slope),\n",
    "             eye=rel_from_signal(eye) * eye_valid)\n",
    "\n",
    "    return dict(t=t, eeg=eeg, eeg_slope=eeg_slope, emg=emg, emg_grad=emg_grad,\n",
    "                eye=eye, R=R, eye_valid=eye_valid)\n",
    "\n",
    "# ======================= MODE & FUSION ===============================\n",
    "def mode_from_filename(stem: str) -> Optional[str]:\n",
    "    m = re.search(r'(?:^|_)(T|M)(\\d{2,})', stem, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        return None\n",
    "    return 'physical' if m.group(1).upper() == 'T' else 'imagery'\n",
    "\n",
    "\n",
    "def infer_mode_from_signals(feats) -> str:\n",
    "    emg = feats['emg']; eeg_slope = feats['eeg_slope']\n",
    "    emg_p95, emg_med = np.nanpercentile(emg,95), np.nanmedian(emg)\n",
    "    eeg_neg = np.nanmedian(eeg_slope[:max(5, int(0.6*len(eeg_slope)))])\n",
    "    score = 0.7*(emg_p95 - 1.5*emg_med) - 0.3*(eeg_neg)\n",
    "    return 'physical' if score > 0.4 else 'imagery'\n",
    "\n",
    "def choose_mode(stem: str, feats) -> Tuple[str, str]:\n",
    "    if FORCE_MODE in ('physical','imagery'):\n",
    "        return FORCE_MODE, 'forced'\n",
    "    if MODE_POLICY == 'filename':\n",
    "        m = mode_from_filename(stem)\n",
    "        return (m or 'imagery', 'filename' if m else 'infer')\n",
    "    if MODE_POLICY == 'infer':\n",
    "        return infer_mode_from_signals(feats), 'infer'\n",
    "    m = mode_from_filename(stem)\n",
    "    return (m, 'filename') if m else (infer_mode_from_signals(feats), 'infer')\n",
    "\n",
    "def adaptive_weights(mode, R, eye_valid, eye_valid_min):\n",
    "    if mode == 'physical': base = dict(emg=0.60, eeg=0.30, eye=0.10)\n",
    "    else:                  base = dict(emg=0.15, eeg=0.75, eye=0.10)\n",
    "    w = {k: v*(0.5 + 0.5*min(3.0, R.get(k,0.0))) for k,v in base.items()}\n",
    "    if eye_valid < BASE['eye_valid_min']: w['eye'] *= 0.10\n",
    "    s = sum(w.values()) + 1e-12\n",
    "    return {k: v/s for k,v in w.items()}\n",
    "\n",
    "def fuse_score(feats, weights):\n",
    "    return (weights['eeg']*feats['eeg'] + weights['emg']*feats['emg'] + weights['eye']*feats['eye'])\n",
    "\n",
    "# ======================= EMISSIONS & PRIOR ===========================\n",
    "def _fit_two_gaussians(x):\n",
    "    x = np.asarray(x); x = x[np.isfinite(x)]\n",
    "    if x.size < 64:\n",
    "        m = np.nanmedian(x); s = np.nanstd(x) + 1e-6\n",
    "        return (m-0.5*s, 0.7*s), (m+0.7*s, 0.7*s)\n",
    "    if USE_SKLEARN_GMM:\n",
    "        try:\n",
    "            from sklearn.mixture import GaussianMixture\n",
    "            gm = GaussianMixture(n_components=2, covariance_type='spherical', random_state=0)\n",
    "            gm.fit(x.reshape(-1,1))\n",
    "            means = gm.means_.ravel()\n",
    "            stds  = np.sqrt(gm.covariances_.ravel()) + 1e-9\n",
    "            idx = np.argsort(means)\n",
    "            return (float(means[idx[0]]), float(stds[idx[0]])), (float(means[idx[1]]), float(stds[idx[1]]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    hist, edges = np.histogram(x, bins=128)\n",
    "    p = hist / max(1, hist.sum())\n",
    "    omega = np.cumsum(p)\n",
    "    centers = (edges[:-1] + edges[1:]) / 2.0\n",
    "    mu = np.cumsum(p * centers); mu_t = mu[-1]\n",
    "    sigma_b2 = (mu_t*omega - mu)**2 / (omega*(1.0 - omega) + 1e-12)\n",
    "    idx = int(np.nanargmax(sigma_b2))\n",
    "    thr = (edges[idx] + edges[idx+1]) / 2\n",
    "    lo = x[x <= thr]; hi = x[x > thr]\n",
    "    if lo.size < 8 or hi.size < 8:\n",
    "        m = np.nanmedian(x); s = np.nanstd(x) + 1e-6\n",
    "        return (m-0.5*s, 0.7*s), (m+0.7*s, 0.7*s)\n",
    "    means = np.array([np.mean(lo), np.mean(hi)])\n",
    "    stds  = np.array([np.std(lo)+1e-9, np.std(hi)+1e-9])\n",
    "    order = np.argsort(means)\n",
    "    return (float(means[order[0]]), float(stds[order[0]])), (float(means[order[1]]), float(stds[order[1]]))\n",
    "\n",
    "def _logN(x, mu, s):\n",
    "    v = (x - mu) / (s + 1e-12)\n",
    "    return -0.5*(v**2) - np.log(s + 1e-12) - 0.5*np.log(2*np.pi)\n",
    "\n",
    "def _lognorm_params_from_quantiles(q_lo, q_hi, p_lo=0.025, p_hi=0.975):\n",
    "    a, b = np.log(q_lo+1e-9), np.log(q_hi+1e-9)\n",
    "    z_lo, z_hi = norm.ppf(p_lo), norm.ppf(p_hi)\n",
    "    sigma = (b - a) / max(1e-9, (z_hi - z_lo))\n",
    "    mu = a - z_lo*sigma\n",
    "    return mu, sigma\n",
    "\n",
    "def duration_prior_log(d_range_s, mode, fs):\n",
    "    lo, hi = BASE['target_dur_physical'] if mode=='physical' else BASE['target_dur_imagery']\n",
    "    mu, sig = _lognorm_params_from_quantiles(lo, hi, 0.025, 0.975)\n",
    "    d_s = np.asarray(d_range_s)\n",
    "    pdf = (1.0/(d_s*sig*np.sqrt(2*np.pi)+1e-12))*np.exp(-(np.log(d_s+1e-12)-mu)**2/(2*sig*sig))\n",
    "    pdf = np.clip(pdf, 1e-12, None); pdf /= np.sum(pdf)\n",
    "    return np.log(pdf)\n",
    "\n",
    "# ======================= HSMM SINGLE-SEGMENT =========================\n",
    "def hsmm_single_segment(smooth, fs, mode):\n",
    "    x = np.asarray(smooth)\n",
    "    (mu0,s0), (mu1,s1) = _fit_two_gaussians(x)\n",
    "    ll0 = _logN(x, mu0, s0); ll1 = _logN(x, mu1, s1)\n",
    "    delta = ll1 - ll0; csum = np.cumsum(np.r_[0.0, delta])\n",
    "\n",
    "    T = len(x)\n",
    "    d_max = int(min(T, (BASE['target_dur_physical'][1] if mode=='physical' else BASE['target_dur_imagery'][1])*fs)+1)\n",
    "    d_min = int(max(1, (BASE['target_dur_physical'][0] if mode=='physical' else BASE['target_dur_imagery'][0])*fs))\n",
    "    d_vals = np.arange(1, d_max+1, dtype=int); d_secs = d_vals / fs\n",
    "    log_p_d = duration_prior_log(d_secs, mode, fs)\n",
    "\n",
    "    best_score = -1e18; best_e = -1; best_d = -1\n",
    "    for e in range(1, T+1):\n",
    "        d_hi = min(e, d_max); d_lo = min(e, max(1, d_min))\n",
    "        local_best = -1e18; local_d = -1\n",
    "        for d in range(d_lo, d_hi+1):\n",
    "            s = e - d\n",
    "            score = (csum[e] - csum[s]) + log_p_d[d-1]\n",
    "            if score > local_best:\n",
    "                local_best = score; local_d = d\n",
    "        if local_best > best_score:\n",
    "            best_score = local_best; best_e = e; best_d = local_d\n",
    "\n",
    "    s_idx = max(0, best_e - best_d); e_idx = max(0, best_e - 1)\n",
    "    params = dict(mu_rest=float(mu0), sd_rest=float(s0), mu_act=float(mu1), sd_act=float(s1))\n",
    "    diag   = dict(delta=delta, csum=csum, log_p_d=log_p_d, d_vals=d_vals)\n",
    "    return s_idx, e_idx, params, diag\n",
    "\n",
    "# ======================= BOUNDARY REFINEMENT =========================\n",
    "def refine_boundaries(feats, s_idx, e_idx, fs, mode):\n",
    "    T = len(feats['t'])\n",
    "    def sustain_mask(mask, min_sec):\n",
    "        n = max(1, int(min_sec*fs))\n",
    "        if n == 1: return mask\n",
    "        run = np.convolve(mask.astype(int), np.ones(n, int), 'same') >= n\n",
    "        return run\n",
    "\n",
    "    if mode == 'physical':\n",
    "        back = int(BASE['phys_backseek_s']*fs); fwd  = int(BASE['phys_forward_s']*fs)\n",
    "        emg_grad = feats['emg_grad']; emg = feats['emg']\n",
    "        on_mask = (emg_grad > BASE['phys_on_grad_thr']) | (emg > BASE['phys_on_env_thr'])\n",
    "        on_mask = sustain_mask(on_mask, BASE['phys_min_sustain_s'])\n",
    "        cand = _first_true_in_window(on_mask, max(0, s_idx - back), s_idx)\n",
    "        if cand is not None: s_idx = cand\n",
    "        off_mask = sustain_mask(emg > BASE['phys_off_env_thr'], BASE['phys_min_sustain_s'])\n",
    "        cand2 = _last_true_in_window(off_mask, e_idx, min(T-1, e_idx + fwd))\n",
    "        if cand2 is not None: e_idx = max(cand2, s_idx+1)\n",
    "    else:\n",
    "        back = int(BASE['imag_backseek_s']*fs); fwd  = int(BASE['imag_forward_s']*fs)\n",
    "        eeg_slope = feats['eeg_slope']; eeg = feats['eeg']\n",
    "        on_mask = (eeg_slope < BASE['imag_on_slope_thr']) & (eeg < BASE['imag_on_eeg_thr'])\n",
    "        on_mask = sustain_mask(on_mask, BASE['imag_min_sustain_s'])\n",
    "        cand = _first_true_in_window(on_mask, max(0, s_idx - back), s_idx)\n",
    "        if cand is not None: s_idx = cand\n",
    "        off_mask = sustain_mask(np.abs(eeg) > BASE['imag_off_abs_thr'], BASE['imag_min_sustain_s'])\n",
    "        cand2 = _last_true_in_window(off_mask, e_idx, min(T-1, e_idx + fwd))\n",
    "        if cand2 is not None: e_idx = max(cand2, s_idx+1)\n",
    "\n",
    "    s_idx = int(max(0, min(s_idx, T-2)))\n",
    "    e_idx = int(max(s_idx+1, min(e_idx, T-1)))\n",
    "    return s_idx, e_idx\n",
    "\n",
    "# ======================= SHIELDS (with clamps) =======================\n",
    "def _sustain(mask: np.ndarray, fs: float, dur_s: float) -> np.ndarray:\n",
    "    n = max(1, int(dur_s*fs))\n",
    "    return np.convolve(mask.astype(int), np.ones(n, int), 'same') >= n\n",
    "\n",
    "def compute_rest_shields(feats, fused, fs):\n",
    "    \"\"\"\n",
    "    Learn head/tail baselines; detect earliest activation & latest rest.\n",
    "    Then clamp: pre-rest ∈ [3,4] s; post-rest ∈ [1,4] s (nominal).\n",
    "    \"\"\"\n",
    "    T = len(feats['t'])\n",
    "    if T == 0: return 0, 0\n",
    "\n",
    "    z_fused = robust_z(fused)\n",
    "    z_combo = 0.6*feats['emg'] + 0.3*z_fused + 0.1*feats['eye']\n",
    "\n",
    "    # ---- PRE (forward) in [3,4] s window\n",
    "    pre_min_idx = int(min(T-1, PRE_REST_MIN_S * fs))\n",
    "    pre_max_idx = int(min(T-1, PRE_REST_MAX_S * fs))\n",
    "\n",
    "    base_n   = max(5, int(PRE_BASELINE_S * fs))\n",
    "    base_pre = z_combo[:base_n] if base_n < T else z_combo[:max(5, T//6)]\n",
    "    thr_on   = float(np.nanmedian(base_pre)) + ON_Z_K * float(mad(base_pre) + 1e-9)\n",
    "\n",
    "    ma = rolling_mean(z_combo, int(0.08 * fs))\n",
    "    act = _sustain(ma > thr_on, fs, MIN_SUSTAIN_ON_S)\n",
    "\n",
    "    first_cross = _first_true_in_window(act, lo=pre_min_idx, hi=pre_max_idx)\n",
    "    if first_cross is None:\n",
    "        pre_end_idx = int(min(T-1, round(3.5 * fs)))  # midpoint if no crossing\n",
    "    else:\n",
    "        pre_end_idx = first_cross - int(BACKOFF_ON_S * fs)\n",
    "\n",
    "    pre_end_idx = int(np.clip(pre_end_idx, pre_min_idx, pre_max_idx))\n",
    "\n",
    "    # ---- POST (backward) yielding 1–4 s tail rest (nominal)\n",
    "    post_earliest_idx = max(0, T - int(POST_REST_MAX_S * fs))  # ≥ T-4s\n",
    "    post_latest_idx   = max(0, T - int(POST_REST_MIN_S * fs))  # ≤ T-1s\n",
    "\n",
    "    tail_slice  = z_combo[max(0, T - max(5, int(POST_BASELINE_S*fs))):]\n",
    "    thr_rest    = float(np.nanmedian(tail_slice)) + OFF_Z_K * float(mad(tail_slice) + 1e-9)\n",
    "\n",
    "    ma2 = rolling_mean(z_combo, int(0.10 * fs))\n",
    "    is_rest = _sustain(ma2 <= thr_rest, fs, MIN_SUSTAIN_OFF_S)\n",
    "\n",
    "    last_rest_rev = _first_true_in_window(is_rest[::-1], lo=0, hi=int(POST_REST_MAX_S * fs))\n",
    "    if last_rest_rev is None:\n",
    "        post_start_idx = post_latest_idx\n",
    "    else:\n",
    "        rr = T - 1 - (last_rest_rev - 1 if last_rest_rev > 0 else 0)\n",
    "        post_start_idx = rr + int(BACKOFF_OFF_S * fs)\n",
    "\n",
    "    post_start_idx = max(post_start_idx, post_earliest_idx)\n",
    "    post_start_idx = min(post_start_idx, post_latest_idx)\n",
    "    post_start_idx = int(np.clip(post_start_idx, 0, T))\n",
    "\n",
    "    if pre_end_idx >= post_start_idx:\n",
    "        mid = (pre_end_idx + post_start_idx)//2\n",
    "        pre_end_idx = max(0, mid - int(0.25*fs))\n",
    "        post_start_idx = min(T, pre_end_idx + int(0.50*fs))\n",
    "    return int(pre_end_idx), int(post_start_idx)\n",
    "\n",
    "# -------- Tail extension via EMG quiet-window (robust, no truncation) --------\n",
    "def extend_action_tail_emg_quiet(feats, fs, s_idx, e_idx):\n",
    "    \"\"\"\n",
    "    From HSMM/refined offset, extend until we hit a sustained quiet window,\n",
    "    defined by:\n",
    "      - EMG envelope near pre-rest baseline (median + REST_K*MAD),\n",
    "      - EMG gradient below GRAD_QUIET_THR,\n",
    "      - sustained for TAIL_QUIET_S seconds.\n",
    "    \"\"\"\n",
    "    T = len(feats['t']); env = feats['emg']; grad = feats['emg_grad']\n",
    "\n",
    "    # Pre-rest baseline from first 2 s (or PRE_REST_MIN_S if shorter)\n",
    "    pre_win = int(max(1, min(PRE_REST_MIN_S*fs, 2.0*fs)))\n",
    "    base = env[:pre_win] if pre_win < T else env[:max(5, T//6)]\n",
    "    rest_thr = float(np.nanmedian(base)) + REST_K * float(mad(base) + 1e-9)\n",
    "\n",
    "    # Quiet if both envelope is low and gradient is low\n",
    "    env_ok  = env <= rest_thr\n",
    "    grad_ok = grad <= GRAD_QUIET_THR\n",
    "    quiet   = env_ok & grad_ok\n",
    "    quiet_sustain = _sustain(quiet, fs, TAIL_QUIET_S)\n",
    "\n",
    "    # Search forward for first quiet window after the current offset\n",
    "    search_lo = int(min(T-1, e_idx + int(0.05*fs)))\n",
    "    search_hi = int(min(T-1, e_idx + int(TAIL_EXTEND_MAX_S*fs)))\n",
    "    q_start = _first_true_in_window(quiet_sustain, search_lo, search_hi)\n",
    "\n",
    "    if q_start is None:\n",
    "        # No quiet found — extend to the cap\n",
    "        new_e = search_hi\n",
    "    else:\n",
    "        new_e = max(e_idx, q_start - int(TAIL_BACKOFF_S*fs))\n",
    "\n",
    "    return int(min(T-1, new_e))\n",
    "\n",
    "# ======================= FINALIZE HELPERS ============================\n",
    "def refine_active_mask(mask: np.ndarray, fs: float,\n",
    "                       min_bout_s: float = MIN_BOUT_S,\n",
    "                       max_gap_s: float = MAX_GAP_S) -> np.ndarray:\n",
    "    x = np.asarray(mask, dtype=np.uint8).copy()\n",
    "    if x.size == 0: return x\n",
    "    min_bout = max(1, int(round(min_bout_s * fs)))\n",
    "    max_gap  = max(1, int(round(max_gap_s  * fs)))\n",
    "\n",
    "    def runs(arr):\n",
    "        d = np.diff(np.r_[0, arr, 0])\n",
    "        starts = np.where(d == 1)[0]; ends   = np.where(d == -1)[0]\n",
    "        out = []; prev = 0\n",
    "        for s,e in zip(starts, ends):\n",
    "            if s > prev: out.append((prev, s, 0))\n",
    "            out.append((s, e, 1)); prev = e\n",
    "        if prev < len(arr): out.append((prev, len(arr), 0))\n",
    "        return out\n",
    "\n",
    "    for s,e,v in runs(x):\n",
    "        if v == 1 and (e - s) < min_bout: x[s:e] = 0\n",
    "    r = runs(x)\n",
    "    for i in range(1, len(r)-1):\n",
    "        s,e,v = r[i]\n",
    "        if v == 0 and (e - s) <= max_gap and r[i-1][2] == 1 and r[i+1][2] == 1:\n",
    "            x[s:e] = 1\n",
    "    return x\n",
    "\n",
    "def segments_from_mask(mask: np.ndarray):\n",
    "    x = np.asarray(mask, dtype=np.uint8)\n",
    "    d = np.diff(np.r_[0, x, 0])\n",
    "    starts = np.where(d == 1)[0]; ends   = np.where(d == -1)[0]\n",
    "    return list(zip(starts, ends))\n",
    "\n",
    "# ============================ PLOTTING ===============================\n",
    "def plot_results_basic(df, feats, fused, start_s, end_s, smooth, hsmm_params, save_path=None, title_suffix=\"\"):\n",
    "    t = feats['t']\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(16, 12))\n",
    "\n",
    "    axes[0].plot(t, fused, lw=2, alpha=0.9, label='Fused Score')\n",
    "    axes[0].plot(t, smooth, alpha=0.35, label='Smoothed')\n",
    "    axes[0].axvspan(start_s, end_s, color='purple', alpha=0.2, label='HSMM+Refined')\n",
    "    axes[0].axhline(hsmm_params['mu_rest'], ls='--', alpha=0.6, label='μ_rest (unsup)')\n",
    "    axes[0].axhline(hsmm_params['mu_act'],  ls='--', alpha=0.6, label='μ_action (unsup)')\n",
    "    axes[0].axvspan(t[0], start_s, color='k', alpha=0.05, hatch='///', label='Pre-rest (learned)')\n",
    "    axes[0].axvspan(end_s, t[-1], color='k', alpha=0.05, hatch='\\\\\\\\\\\\', label='Post-rest (learned)')\n",
    "    axes[0].set_ylabel('Z-score'); axes[0].grid(True, alpha=0.3); axes[0].legend(loc='upper right')\n",
    "    axes[0].set_title('ICML: HSMM Single-Action Decode ' + title_suffix, fontweight='bold')\n",
    "\n",
    "    axes[1].plot(t, feats['eeg'], lw=1.5, label='EEG Activity')\n",
    "    axes[1].plot(t, feats['emg'], lw=1.5, label='EMG Activity')\n",
    "    axes[1].plot(t, feats['eye'], lw=1.5, label='EYE Activity')\n",
    "    axes[1].axvspan(start_s, end_s, color='gray', alpha=0.15)\n",
    "    axes[1].set_ylabel('Z-score'); axes[1].grid(True, alpha=0.3); axes[1].legend(loc='upper right')\n",
    "    axes[1].set_title('Modality Contributions', fontweight='bold')\n",
    "\n",
    "    emg_cols = [c for c in ['EMG_Ch1','EMG_Ch2','EMG_Ch3','EMG_Ch4'] if c in df.columns]\n",
    "    if emg_cols:\n",
    "        for ch in emg_cols:\n",
    "            axes[2].plot(df['Timestamp_seconds'], df[ch].to_numpy(), lw=0.8, alpha=0.85, label=ch)\n",
    "        axes[2].axvspan(start_s, end_s, color='red', alpha=0.2)\n",
    "        axes[2].set_ylabel('EMG (arb)'); axes[2].legend(ncol=min(2,len(emg_cols)), loc='upper right')\n",
    "        axes[2].grid(True, alpha=0.3); axes[2].set_title('EMG Execution', fontweight='bold')\n",
    "\n",
    "    eeg_cols = [c for c in [f'EEG_Ch{i}' for i in range(1,9)] if c in df.columns][:3]\n",
    "    if eeg_cols:\n",
    "        for i, ch in enumerate(eeg_cols):\n",
    "            x = df[ch].ffill().bfill().to_numpy()\n",
    "            xn = (x - np.mean(x)) / (np.std(x)+1e-12)\n",
    "            axes[3].plot(df['Timestamp_seconds'], xn + 4*i, lw=1.0, alpha=0.9, label=ch)\n",
    "        axes[3].axvspan(start_s, end_s, color='blue', alpha=0.2)\n",
    "        axes[3].set_ylabel('EEG (norm)'); axes[3].legend(loc='upper right')\n",
    "        axes[3].grid(True, alpha=0.3); axes[3].set_title('EEG Preparation', fontweight='bold')\n",
    "\n",
    "    lab = np.where((t>=start_s)&(t<=end_s),1,0)\n",
    "    axes[4].step(t, lab, where='post', lw=3, label='Action Label')\n",
    "    axes[4].set_yticks([0,0.5,1]); axes[4].set_yticklabels(['Rest','0.5','Action'])\n",
    "    axes[4].set_ylim(-0.1,1.1); axes[4].grid(True, alpha=0.3)\n",
    "    axes[4].set_xlabel('Time (s)'); axes[4].set_ylabel('Action / Prob.')\n",
    "    axes[4].legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path: fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    return fig\n",
    "\n",
    "def plot_results_extended(df, feats, fused, start_s, end_s, fs, smooth, hsmm_params, hsmm_diag,\n",
    "                          pre_end_idx: int, post_start_idx: int,\n",
    "                          save_path=None, title_suffix=\"\"):\n",
    "    t = feats['t']; n_rows = 7 + (1 if ADD_SPECTROGRAM else 0)\n",
    "    fig = plt.figure(figsize=(16, 3*n_rows + 2))\n",
    "    gs = gridspec.GridSpec(n_rows, 1, figure=fig, hspace=0.35); r = 0\n",
    "\n",
    "    t_roi = t[pre_end_idx:post_start_idx]; delta = hsmm_diag['delta']; csum  = hsmm_diag['csum']\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    ax.plot(t, fused, lw=2, label='Fused Score')\n",
    "    ax.plot(t, smooth, alpha=0.35, label='Smoothed')\n",
    "    ax.axvspan(start_s, end_s, color='purple', alpha=0.20, label='HSMM+Refined')\n",
    "    ax.axhline(hsmm_params['mu_rest'],  ls='--', alpha=0.6, label='μ_rest')\n",
    "    ax.axhline(hsmm_params['mu_act'],   ls='--', alpha=0.6, label='μ_act')\n",
    "    ax.axvspan(t[0], start_s, color='k', alpha=0.05, hatch='///', label='Pre-rest')\n",
    "    ax.axvspan(end_s, t[-1], color='k', alpha=0.05, hatch='\\\\\\\\\\\\', label='Post-rest')\n",
    "    ax.set_ylabel('Z'); ax.set_title(f'HSMM Decode — {title_suffix}'); ax.grid(True, alpha=0.3); ax.legend(loc='upper right')\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    ax.plot(t_roi, delta, lw=1.1, label='Δ logL (act - rest)')\n",
    "    ax2 = ax.twinx(); ax2.plot(t_roi, csum[1:], lw=1.1, alpha=0.6, label='cum Δ logL', linestyle='--')\n",
    "    ax.axvspan(start_s, end_s, color='gray', alpha=0.12)\n",
    "    ax.set_title('Likelihood Terms'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    ax.plot(t, feats['emg'], label='EMG envelope (z)', lw=1.5)\n",
    "    ax.plot(t, feats['emg_grad'], label='EMG gradient (z)', lw=1.0, alpha=0.85)\n",
    "    ax.axvspan(start_s, end_s, color='red', alpha=0.12)\n",
    "    ax.set_title('EMG Evidence'); ax.grid(True, alpha=0.3); ax.legend(loc='upper right')\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    ax.plot(t, feats['eeg_slope'], label='EEG MRCP slope (z)', lw=1.2)\n",
    "    ax.plot(t, feats['eeg'],       label='EEG combined (z)', lw=1.2, alpha=0.9)\n",
    "    ax.axvspan(start_s, end_s, color='blue', alpha=0.12)\n",
    "    ax.set_title('EEG Evidence'); ax.grid(True, alpha=0.3); ax.legend(loc='upper right')\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    ax.plot(t, feats['eye'], label='Eye activity (z)', lw=1.2)\n",
    "    ax.axvspan(start_s, end_s, color='green', alpha=0.10)\n",
    "    ax.set_title('Oculomotor Evidence'); ax.grid(True, alpha=0.3); ax.legend(loc='upper right')\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    R = feats['R']; keys = ['EMG','EEG','Eye']; vals = [R['emg'], R['eeg'], R['eye']]\n",
    "    ax.bar(keys, vals); ax.set_ylim(0, max(1.0, max(vals)+0.1))\n",
    "    ax.set_title('Modality Reliability (relative)'); ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "    d_vals = hsmm_diag['d_vals']; log_p = hsmm_diag['log_p_d']\n",
    "    secs = d_vals / fs; ax.plot(secs, np.exp(log_p), lw=1.5)\n",
    "    ax.set_xlabel('Duration (s)'); ax.set_ylabel('Prior p(d)'); ax.set_title('HSMM Duration Prior'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if ADD_SPECTROGRAM:\n",
    "        eeg_cols = [c for c in [f'EEG_Ch{i}' for i in range(1,9)] if c in df.columns]\n",
    "        if eeg_cols:\n",
    "            ax = fig.add_subplot(gs[r, 0]); r += 1\n",
    "            x = df[eeg_cols[0]].ffill().bfill().to_numpy()\n",
    "            nper = int(fs*1.0); nover = int(fs*0.9)\n",
    "            f, tt_spec, Sxx = _sig.spectrogram(x, fs=fs, nperseg=nper, noverlap=nover,\n",
    "                                               scaling='spectrum', mode='psd')\n",
    "            keep = (f>=1) & (f<=40)\n",
    "            im = ax.pcolormesh(tt_spec, f[keep], 10*np.log10(Sxx[keep,:]+1e-12), shading='auto')\n",
    "            ax.axvspan(start_s, end_s, color='purple', alpha=0.15)\n",
    "            ax.set_ylabel('Hz'); ax.set_xlabel('Time (s)'); ax.set_title(f'EEG Spectrogram ({eeg_cols[0]})')\n",
    "            cb = fig.colorbar(im, ax=ax, fraction=0.02, pad=0.02); cb.set_label('Power (dB)')\n",
    "\n",
    "    fig.suptitle('ICML Extended Diagnostics (HSMM + Head Clamp + EMG Tail Recovery)', fontsize=14, fontweight='bold', y=0.995)\n",
    "    fig.tight_layout()\n",
    "    if save_path: fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    return fig\n",
    "\n",
    "# ============================ FILE PROCESS ===========================\n",
    "def parse_ids_from_stem(stem: str, input_dir: Path):\n",
    "    \"\"\"\n",
    "    subject_id is taken from the folder name like 'Sub-6',\n",
    "    but we store only the numeric part → 6 (not 'Sub-6').\n",
    "\n",
    "    Filename convention (your rule):\n",
    "        ...T114...  → task=1, trial=14\n",
    "        ...T216...  → task=2, trial=16\n",
    "        ...M305...  → imagery: task=3, trial=5\n",
    "    i.e., FIRST digit after T/M = task, REMAINING digits = trial.\n",
    "    \"\"\"\n",
    "    subj = None\n",
    "    # walk up directory tree looking for 'Sub-<num>' or 'sub<num>' or 'sub-<num>'\n",
    "    for part in input_dir.parts[::-1]:\n",
    "        m = re.match(r'(?i)^sub-?(\\d+)$', part)\n",
    "        if m:\n",
    "            subj = int(m.group(1))  # store as 6, not 'Sub-6'\n",
    "            break\n",
    "\n",
    "    mode = None\n",
    "    task = None\n",
    "    trial = None\n",
    "\n",
    "    # Allow codes at start OR after an underscore:\n",
    "    # matches: \"T216...\", \"Sub-2_T216_synchronized_corrected\", \"M114\", etc.\n",
    "    m = re.search(r'(?:^|_)(T|M)(\\d{2,})', stem, flags=re.I)\n",
    "    if m:\n",
    "        mode = m.group(1).upper()\n",
    "        digits = m.group(2)\n",
    "\n",
    "        # Your convention: first digit = task, rest = trial\n",
    "        # e.g., \"216\" -> task=2, trial=16; \"114\" -> task=1, trial=14\n",
    "        if len(digits) >= 2:\n",
    "            task  = int(digits[0])\n",
    "            trial = int(digits[1:])\n",
    "        else:\n",
    "            # Just in case of weird filenames like T2 (no trial info)\n",
    "            task  = int(digits)\n",
    "            trial = -1\n",
    "\n",
    "    return subj, mode, task, trial\n",
    "\n",
    "\n",
    "\n",
    "def process_file(path: str, label_dir: Path, plots_dir: Path) -> dict:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    df = canonicalize_columns(df)\n",
    "\n",
    "    if 'Timestamp_seconds' not in df.columns:\n",
    "        if 'Timestamp_ms' in df.columns:\n",
    "            df['Timestamp_seconds'] = df['Timestamp_ms'].astype(float)/1000.0\n",
    "        elif 'ET_TimeSignal' in df.columns:\n",
    "            df['Timestamp_seconds'] = df['ET_TimeSignal'].astype(float)\n",
    "        else:\n",
    "            raise ValueError(f\"{Path(path).name}: missing time column\")\n",
    "\n",
    "    stem = Path(path).stem\n",
    "    subj, mode_tok, task, trial = parse_ids_from_stem(stem, label_dir.parent)\n",
    "\n",
    "    t  = df['Timestamp_seconds'].astype(float).to_numpy()\n",
    "    fs = median_fs(t); T = len(t)\n",
    "\n",
    "    et_present = _et_signal_audit(df)\n",
    "    print(f\"[ET] {Path(path).name} → pupil:{len(et_present['pupil'])>0} \"\n",
    "          f\"gazeXY:{len(et_present['gaze_xy'])>0} valid:{len(et_present['valid'])>0} \"\n",
    "          f\"axis3d:{len(et_present['fallback_axis'])>0} imu:{len(et_present['imu'])>0} events:{len(et_present['events'])>0}\")\n",
    "\n",
    "    feats = extract_features(df, fs)\n",
    "\n",
    "    if FORCE_MODE in ('physical','imagery'): \n",
    "        mode, mode_source = FORCE_MODE, 'forced'\n",
    "    else:\n",
    "        if MODE_POLICY in {'auto','filename'} and mode_tok is not None:\n",
    "            mode = 'physical' if mode_tok == 'T' else 'imagery'; mode_source = 'filename'\n",
    "        elif MODE_POLICY == 'infer':\n",
    "            mode, mode_source = infer_mode_from_signals(feats), 'infer'\n",
    "        else:\n",
    "            mode, mode_source = choose_mode(stem, feats)\n",
    "\n",
    "    smooth_win = BASE['smooth_win_physical'] if mode=='physical' else (\n",
    "                 BASE['smooth_win_imagery'] if mode=='imagery' else BASE['smooth_win_default'])\n",
    "\n",
    "    weights = adaptive_weights(mode, feats['R'], feats['eye_valid'], BASE['eye_valid_min'])\n",
    "    fused   = fuse_score(feats, weights)\n",
    "    smooth  = np.convolve(fused, np.ones(smooth_win)/smooth_win, 'same')\n",
    "\n",
    "    # >>> REST-ONLY BYPASS (T0x) <<<\n",
    "    # If filename encodes Task 0 (e.g., ..._T02_... → task=0, trial=2), treat as pure REST.\n",
    "    if (mode_tok == 'T' and task == 0):\n",
    "        pre_end_idx, post_start_idx = compute_rest_shields(feats, fused, fs)\n",
    "        out_df = df.copy()\n",
    "        # zero labels\n",
    "        out_df['active_raw']   = 0\n",
    "        out_df['active']       = 0\n",
    "        out_df['active_prob']  = 0.0\n",
    "        out_df['label_action'] = 0\n",
    "        # meta columns\n",
    "        if subj is not None:  out_df['subject_id'] = subj\n",
    "        if task is not None:  out_df['task'] = task\n",
    "        if trial is not None: out_df['trial'] = trial\n",
    "        out_df['label_11']   = 0\n",
    "        out_df['task_target']= 0\n",
    "\n",
    "        sidecar = {\n",
    "            \"file\": str(Path(path).resolve()),\n",
    "            \"subject_id\": subj,\n",
    "            \"task_code\": int(task) if task is not None else 0,\n",
    "            \"trial_id\": int(trial) if trial is not None else -1,\n",
    "            \"fs_hz\": float(fs),\n",
    "            \"duration_s\": float(t[-1]-t[0]) if T else 0.0,\n",
    "            \"n_active_segments\": 0,\n",
    "            \"segments\": [],\n",
    "            \"rest_shields\": {\n",
    "                \"pre_rest_end_s\":  float(t[min(pre_end_idx,  T-1)]),\n",
    "                \"post_rest_start_s\": float(t[min(post_start_idx, T-1)])\n",
    "            }\n",
    "        }\n",
    "        label_dir.mkdir(parents=True, exist_ok=True); plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(label_dir / f\"{stem}_onsets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(sidecar, f, indent=2)\n",
    "\n",
    "        out_csv = str(label_dir / f\"{stem}_icml_consensus_labels.csv\")\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "\n",
    "        return dict(file=Path(path).name, subject_id=subj, mode='physical', mode_source='forced',\n",
    "                    fs=round(fs,2), start_s=None, end_s=None, duration_s=0.0,\n",
    "                    mu_rest=np.nan, sd_rest=np.nan, mu_act=np.nan, sd_act=np.nan,\n",
    "                    out_csv=out_csv, out_png_basic=None, out_png_ext=None, quality=\"REST_ONLY\")\n",
    "\n",
    "    # ----------- SHIELDS + CLAMP of ROI -----------\n",
    "    pre_end_idx, post_start_idx = compute_rest_shields(feats, fused, fs)\n",
    "    # Clamp ROI start to [3,4] s (strict head rest)\n",
    "    min_on = int(PRE_REST_MIN_S*fs); max_on = int(PRE_REST_MAX_S*fs)\n",
    "    pre_end_idx = int(np.clip(pre_end_idx, min_on, max_on))\n",
    "    post_start_idx = max(post_start_idx, pre_end_idx + int(0.5*fs))  # ensure some room\n",
    "\n",
    "    # HSMM within legal region\n",
    "    smooth_roi = smooth[pre_end_idx:post_start_idx].copy()\n",
    "    if smooth_roi.size < 8:\n",
    "        out_df = df.copy()\n",
    "        out_df['active'] = 0; out_df['active_prob'] = 0.0\n",
    "        out_df['active_raw']=0; out_df['label_11']=0; out_df['task_target']=0\n",
    "        out_df['label_action'] = 0\n",
    "        if subj is not None: out_df['subject_id']=subj\n",
    "        if task is not None: out_df['task']=task\n",
    "        if trial is not None: out_df['trial']=trial\n",
    "        sidecar = {\n",
    "            \"file\": str(Path(path).resolve()),\n",
    "            \"subject_id\": subj, \"task_code\": int(task) if task is not None else 0,\n",
    "            \"trial_id\": int(trial) if trial is not None else -1,\n",
    "            \"fs_hz\": float(fs),\n",
    "            \"duration_s\": float(t[-1]-t[0]) if T else 0.0,\n",
    "            \"n_active_segments\": 0,\n",
    "            \"segments\": [],\n",
    "            \"rest_shields\": {\"pre_rest_end_s\": float(t[min(pre_end_idx, T-1)]),\n",
    "                             \"post_rest_start_s\": float(t[min(post_start_idx, T-1)])}\n",
    "        }\n",
    "        label_dir.mkdir(parents=True, exist_ok=True); plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(label_dir / f\"{stem}_onsets.json\",\"w\",encoding=\"utf-8\") as f: json.dump(sidecar,f,indent=2)\n",
    "        out_csv = str(label_dir / f\"{stem}_icml_consensus_labels.csv\"); out_df.to_csv(out_csv, index=False)\n",
    "        return dict(file=Path(path).name, subject_id=subj, mode='physical', mode_source='forced', fs=round(fs,2),\n",
    "                    start_s=None, end_s=None, duration_s=0.0,\n",
    "                    mu_rest=np.nan, sd_rest=np.nan, mu_act=np.nan, sd_act=np.nan,\n",
    "                    out_csv=out_csv, out_png_basic=None, out_png_ext=None, quality=\"NO-ROOM\")\n",
    "\n",
    "    s_local, e_local, hsmm_params, hsmm_diag = hsmm_single_segment(smooth_roi, fs, mode)\n",
    "    s_idx = pre_end_idx + s_local; e_idx = pre_end_idx + e_local\n",
    "\n",
    "    s_idx_ref, e_idx_ref = refine_boundaries(feats, s_idx, e_idx, fs, mode)\n",
    "    s_idx_ref = max(s_idx_ref, pre_end_idx); e_idx_ref = min(e_idx_ref, post_start_idx-1)\n",
    "\n",
    "    # ---- HARD HEAD RULE: force onset into [3,4] s band\n",
    "    s_idx_ref = int(np.clip(s_idx_ref, min_on, max_on))\n",
    "    pre_end_idx = min(pre_end_idx, s_idx_ref)\n",
    "\n",
    "    # ---- TAIL: EMG quiet-window recovery (robust)\n",
    "    e_idx_ref = extend_action_tail_emg_quiet(feats, fs, s_idx_ref, e_idx_ref)\n",
    "\n",
    "    # ---- Ensure legal tail rest; allow evidence override down to 0.5 s\n",
    "    min_tail = int(POST_REST_MIN_S * fs)\n",
    "    min_tail_relaxed = int(TAIL_OVERRIDE_MIN_REST_S * fs)\n",
    "    post_start_idx = max(post_start_idx, e_idx_ref + min_tail)  # nominal\n",
    "    if post_start_idx > T - 1:  # relax if evidence pushes near end\n",
    "        post_start_idx = min(T-1, e_idx_ref + min_tail_relaxed)\n",
    "    post_start_idx = min(post_start_idx, T-1)\n",
    "\n",
    "    start_s = float(t[s_idx_ref]); end_s = float(t[e_idx_ref]); dur = max(0.0, end_s - start_s)\n",
    "\n",
    "    delta = hsmm_diag['delta']; scale = max(1e-6, mad(smooth_roi))\n",
    "    p_active_roi = 1.0/(1.0 + np.exp(-delta / (BASE['prob_scale_frac']*scale + 1e-12)))\n",
    "\n",
    "    out_df = df.copy()\n",
    "    active = np.zeros(T, dtype=int); active[s_idx_ref:e_idx_ref+1] = 1\n",
    "    active[:pre_end_idx] = 0; active[post_start_idx:] = 0\n",
    "    active_ref = refine_active_mask(active, fs, min_bout_s=MIN_BOUT_S, max_gap_s=MAX_GAP_S)\n",
    "\n",
    "    active_prob = np.zeros(T, float)\n",
    "    roi_len = post_start_idx - pre_end_idx\n",
    "    pa = p_active_roi if np.ndim(p_active_roi)==1 else np.asarray(p_active_roi)\n",
    "    active_prob[pre_end_idx:post_start_idx] = (pa[:roi_len] if pa.size >= roi_len\n",
    "                                               else float(np.nanmean(pa)) if pa.size else 0.0)\n",
    "\n",
    "    out_df['active_raw']=active.astype(int)\n",
    "    out_df['active']=active_ref.astype(int)\n",
    "    out_df['active_prob']=active_prob\n",
    "    out_df['label_action']=out_df['active'].astype(int)  # 0=REST, 1=ACTION\n",
    "\n",
    "    if subj is not None: out_df['subject_id']=subj\n",
    "    if task is not None: out_df['task']=task\n",
    "    if trial is not None: out_df['trial']=trial\n",
    "\n",
    "    task_code = int(task) if task is not None else 0\n",
    "    out_df['label_11'] = np.where(out_df['active']==1, task_code, 0).astype(int)\n",
    "    out_df['task_target'] = out_df['label_11']\n",
    "\n",
    "    segs = segments_from_mask(out_df['active'].to_numpy())\n",
    "    onsets=[]\n",
    "    for s_i, e_i in segs:\n",
    "        s_i=int(s_i); e_i=int(e_i)\n",
    "        s_sec=float(t[s_i]); e_sec=float(t[min(e_i-1, T-1)])\n",
    "        onsets.append({\"start_idx\":s_i,\"end_idx\":e_i,\"start_s\":round(s_sec,6),\n",
    "                       \"end_s\":round(e_sec,6),\"duration_s\":round(max(0.0,e_sec-s_sec),6)})\n",
    "\n",
    "    sidecar = {\n",
    "        \"file\": str(Path(path).resolve()), \"subject_id\": subj,\n",
    "        \"task_code\": task_code, \"trial_id\": int(trial) if trial is not None else -1,\n",
    "        \"fs_hz\": float(fs), \"duration_s\": float(t[-1]-t[0]) if T else 0.0,\n",
    "        \"n_active_segments\": int(len(onsets)), \"segments\": onsets,\n",
    "        \"rest_shields\": {\"pre_rest_end_s\": float(t[min(pre_end_idx, T-1)]),\n",
    "                         \"post_rest_start_s\": float(t[min(post_start_idx, T-1)])}\n",
    "    }\n",
    "    label_dir.mkdir(parents=True, exist_ok=True); plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(label_dir / f\"{stem}_onsets.json\",\"w\",encoding=\"utf-8\") as f: json.dump(sidecar,f,indent=2)\n",
    "\n",
    "    out_csv = str(label_dir / f\"{stem}_icml_consensus_labels.csv\"); out_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    out_png_basic = str(plots_dir / f\"{stem}_icml_detection_plot.png\")\n",
    "    out_png_ext   = str(plots_dir / f\"{stem}_icml_detection_plot_extended.png\")\n",
    "\n",
    "    try:\n",
    "        if SAVE_PLOTS_STANDARD:\n",
    "            fig = plot_results_basic(out_df, feats, fused, float(t[s_idx_ref]), float(t[e_idx_ref]),\n",
    "                                     smooth, hsmm_params,\n",
    "                                     save_path=out_png_basic,\n",
    "                                     title_suffix=f\"(Mode: {mode.upper()} • {mode_source} • Head Clamp + EMG Tail Recovery)\")\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] basic plot failed for {Path(path).name}: {e}\"); out_png_basic=None\n",
    "\n",
    "    try:\n",
    "        if SAVE_PLOTS_EXTENDED:\n",
    "            fig2 = plot_results_extended(out_df, feats, fused, float(t[s_idx_ref]), float(t[e_idx_ref]), fs,\n",
    "                                         smooth, hsmm_params, hsmm_diag,\n",
    "                                         pre_end_idx, post_start_idx,\n",
    "                                         save_path=out_png_ext,\n",
    "                                         title_suffix=f\"Mode: {mode.upper()} • {mode_source} • Head Clamp + EMG Tail Recovery)\")\n",
    "            plt.close(fig2)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] extended plot failed for {Path(path).name}: {e}\"); out_png_ext=None\n",
    "\n",
    "    quality = (\"SHORT\" if (dur < 0.8 and mode=='physical') else\n",
    "               \"LONG\"  if (dur > 8.0 and mode=='physical')  else \"GOOD\")\n",
    "\n",
    "    return dict(file=Path(path).name, subject_id=subj, mode=mode, mode_source=mode_source, fs=round(fs,2),\n",
    "        start_s=round(float(t[s_idx_ref]),3), end_s=round(float(t[e_idx_ref]),3), duration_s=round(dur,3),\n",
    "        mu_rest=round(hsmm_params['mu_rest'],4), sd_rest=round(hsmm_params['sd_rest'],4),\n",
    "        mu_act=round(hsmm_params['mu_act'],4),   sd_act=round(hsmm_params['sd_act'],4),\n",
    "        out_csv=out_csv, out_png_basic=out_png_basic, out_png_ext=out_png_ext, quality=quality)\n",
    "\n",
    "# ============================ SUBJECT RUNNER =========================\n",
    "def process_subject(subject_sync_dir: Path) -> pd.DataFrame:\n",
    "    label_dir = subject_sync_dir / \"label\"\n",
    "    plots_dir = subject_sync_dir / \"plot\"\n",
    "    files = sorted(glob.glob(str(subject_sync_dir/FILE_GLOB)))\n",
    "    if not files:\n",
    "        print(f\"[skip] No files matched in: {subject_sync_dir} | pattern: {FILE_GLOB}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            res = process_file(f, label_dir=label_dir, plots_dir=plots_dir)\n",
    "        except Exception as e:\n",
    "            subj_name = Path(subject_sync_dir).parents[1].name if len(subject_sync_dir.parents) > 1 else None\n",
    "            res = dict(file=Path(f).name, subject_id=subj_name, error=str(e))\n",
    "        results.append(res); print(res)\n",
    "\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        if 'error' in r:\n",
    "            rows.append(dict(file=r['file'], subject_id=r.get('subject_id'), status='ERROR', error=r['error']))\n",
    "        else:\n",
    "            rows.append(dict(file=r['file'], subject_id=r.get('subject_id'), status='OK',\n",
    "                mode=r.get('mode','?'), mode_source=r.get('mode_source','?'), fs=r.get('fs'),\n",
    "                start_s=r.get('start_s'), end_s=r.get('end_s'), duration_s=r.get('duration_s'),\n",
    "                mu_rest=r.get('mu_rest'), sd_rest=r.get('sd_rest'),\n",
    "                mu_act=r.get('mu_act'), sd_act=r.get('sd_act'),\n",
    "                quality=r.get('quality'), out_csv=r.get('out_csv')))\n",
    "    summary = pd.DataFrame(rows)\n",
    "    out_summary = str(subject_sync_dir/\"icml_consensus_batch_summary.csv\")\n",
    "    summary.to_csv(out_summary, index=False)\n",
    "    print(f\"[ok] Subject summary saved: {out_summary}\")\n",
    "    return summary\n",
    "\n",
    "# ---- Notebook-friendly entrypoint ----\n",
    "def main(subject: str | None = None, subject_dir: str | None = None):\n",
    "    if subject_dir: subject_sync_dir = Path(subject_dir)\n",
    "    elif subject:   subject_sync_dir = Path(ROOT_DIR) / subject / Path(SYNC_SUBPATH)\n",
    "    else:           subject_sync_dir = DEFAULT_SUBJECT_SYNC_DIR\n",
    "    print(f\"Processing one subject at: {subject_sync_dir}\")\n",
    "    if not subject_sync_dir.exists():\n",
    "        print(f\"[error] Subject sync dir not found: {subject_sync_dir}\"); return\n",
    "    _ = process_subject(subject_sync_dir)\n",
    "\n",
    "# In Jupyter or script:\n",
    "main(subject_dir=DEFAULT_SUBJECT_SYNC_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
